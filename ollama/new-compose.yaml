version: '3'
networks:
  default:
    name: lusha_net

# yaml anchor
x-ollama: &ollama
  image: ollama/ollama
  environment: &env
    OLLAMA_HOST: "0.0.0.0:11435"
    OLLAMA_DEBUG: 1
    OLLAMA_NUM_PARALLEL: 2
    OLLAMA_CONTEXT_LENGTH: 10240
  user: "${UID-1142}:${GID-1142}"
  ports:  
    - "11435:11435"
  volumes:
    - /multiverse/datasets/shared/ollama_models:/.ollama 
  cpuset: "0-7"
  restart: "no"
  networks:
    - default


services:
  ollama-1:
    << : *ollama
    environment:
      << : [*env]
      OLLAMA_HOST: "0.0.0.0:11435"
    container_name: lusha_ollama1
    ports:
      - "11435:11435"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["3"]
              capabilities: [gpu]

  ollama-2:
    << : *ollama
    environment:
      << : [*env]
      OLLAMA_HOST: "0.0.0.0:11432"
    container_name: lusha_ollama2
    ports:
      - "11432:11432"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["3"]
              capabilities: [gpu]
