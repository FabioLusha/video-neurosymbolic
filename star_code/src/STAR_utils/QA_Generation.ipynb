{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Set, Any\n",
    "from ipywidgets import interact, interact_manual\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from generation_tools.generator import QAGenerator\n",
    "from generation_tools.generation import *\n",
    "\n",
    "from generation_tools.utils.preprocessing import *\n",
    "from generation_tools.utils.postprocessing import *\n",
    "from generation_tools.utils.dict import *\n",
    "from generation_tools.utils.load_save import *\n",
    "from generation_tools.utils.split import *\n",
    "from generation_tools.utils.nlp import *\n",
    "from visualization_tools.qa_visualization import *\n",
    "\n",
    "RANDOM_SEED = 626\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Video Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path Config\n",
    "data_dir = '/root/user/' #'# plase replace following data path to your local path'\n",
    "video_dir= data_dir + 'Charades/'\n",
    "frame_dir = data_dir + 'STAR/frames/Charades_v1_480/'\n",
    "annotation_dir =  data_dir + 'STAR/annotations/'\n",
    "save_dir = data_dir+'/visualization_tmp/'\n",
    "fps_filepath = annotation_dir + 'fps'    \n",
    "# segment_path = annotation_dir + 'segment.json'\n",
    "multi_person_vid = annotation_dir +'multi_person_video_id.json'\n",
    "save_data_dir = data_dir + 'save_dir' #'# plase replace following data path to your local path' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Charades/ActionGenome videos and annotations\n",
    "# Load Videos\n",
    "video_data = load_csv(annotation_dir)\n",
    "video_data = video_data.dropna()\n",
    "\n",
    "# Load Annotations\n",
    "act_map = load_action_mapping(annotation_dir)\n",
    "obj_map = load_obj_mapping(annotation_dir)\n",
    "verb_map = load_verb_mapping(annotation_dir)\n",
    "\n",
    "act_df = pd.DataFrame.from_dict(act_map, orient='index', columns = ['action_cls'] )\n",
    "obj_df = pd.DataFrame.from_dict(obj_map, orient='index', columns = ['obj_cls'] )\n",
    "verb_df = pd.DataFrame.from_dict(verb_map, orient='index', columns = ['verb_cls'] )\n",
    "\n",
    "# Get Frames\n",
    "fps_file = open(fps_filepath, 'rb')\n",
    "fps = pickle.load(fps_file)\n",
    "verb_vocab = list(set([verb_map[x] for x in verb_map.keys()]))\n",
    "\n",
    "## segments (no need for generation)\n",
    "# with open(segment_path, 'r') as f:\n",
    "#    segments = json.load(f)\n",
    "\n",
    "# Per-Obj Relationships and Object Bboxes for Video Frames \n",
    "frame_anno = load_annotations(annotation_dir)\n",
    "anno_video_split = anno_data_split(frame_anno)\n",
    "# anno_video_split['SYMIR']['000188']\n",
    "extend_sg = json.load(open(annotation_dir + 'extend_scene_graph.json'))\n",
    "sg = json.load(open(annotation_dir + 'scene_graph.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter Config\n",
    "video_filtering_cols = ['scene', 'verified', 'quality', 'relevance', 'length', 'actions_num', 'objects_num']\n",
    "cols_to_drop = ['subject']\n",
    "video_verb_list = 'open|close|hold|put|take|throw|grasp|turn|tidy|eat|wash|pour|drink|walk|stand|sit|lie|watch'\n",
    "text_fields = 'script,descriptions'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Videos\n",
    "queried_act_df = act_df[act_df['action_cls'].str.contains(video_verb_list, regex=True)] # verbs in action\n",
    "filtered_videos = video_data[video_data['actions'].str.contains('|'.join(queried_act_df.index), regex=True)] \n",
    "print('The videos with useful verbs:', len(filtered_videos))\n",
    "video_data = filtered_videos\n",
    "\n",
    "video_data['objects_num'] = video_data['objects'].str.count(';')+1\n",
    "video_data['actions_num'] = video_data['actions'].str.count(';')+1\n",
    "video_data = filter_videos(video_data, video_filtering_cols, drop = True)\n",
    "\n",
    "# Preprocessing action data\n",
    "video_data['action_segments'] = video_data['actions'].str.split(';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action space generation\n",
    "def generate_action_data(video_data, verb_map, obj_map):\n",
    "    action_data = video_data['actions'].str.split(';',expand=True).stack().str.split(' ',expand=True)\n",
    "    action_data = action_data.rename(columns={0:'action_id', 1:'start', 2:'end'})\n",
    "    action_data[['start','end']] = action_data[['start','end']].astype(float) \n",
    "    \n",
    "    # sorting by starttime\n",
    "    action_data.index.set_names(['idx1','idx2'],inplace=True)\n",
    "    action_data = action_data.sort_values(['idx1', 'start', 'end'])\n",
    "    \n",
    "    # print(action_data.keys())\n",
    "    action_data['action'] = action_data['action_id'].str.strip().replace(act_map, regex=True)\n",
    "    action_data['verb'] = action_data['action_id'].str.strip().replace(verb_map, regex=True)\n",
    "    action_data['object'] = action_data['action_id'].str.strip().replace(obj_map, regex=True)\n",
    "    \n",
    "    return action_data\n",
    "\n",
    "action_data = generate_action_data(video_data, verb_map, obj_map)\n",
    "print('AG original vocabulary:', action_data[['action_id','verb','object']].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action space filtering \n",
    "\n",
    "# filtering target verbs by verbs or actions\n",
    "eliminated_verbs = 'awaken,play,undress,smile,fix,photograph'.split(',') \n",
    "conditions = ~action_data['verb'].isin(eliminated_verbs)\n",
    "action_data = action_data[conditions]\n",
    "\n",
    "eliminated_action_ids = ['a014',  \n",
    "                        'a020', 'a029', 'a033',\n",
    "                        'a094', 'a115', 'a131'] + ['a' + str(i) for i in range(146,157)] # c146-c156\n",
    "conditions = ~action_data['action_id'].isin(eliminated_action_ids)\n",
    "action_data = action_data[conditions]\n",
    "\n",
    "action_data = action_data[~action_data['action'].str.contains( 'something', regex=True)]\n",
    "\n",
    "# filtering condition verbs by verbs or actions\n",
    "eliminated_verbs = 'undress,sneeze,awaken,snuggle,talk,photograph'.split(',') #, 'cook', 'fix', pour', 'throw', 'leave', 'start', 'begin' ]\n",
    "conditions = ~action_data['verb'].isin(eliminated_verbs)\n",
    "action_data = action_data[conditions]\n",
    "\n",
    "allowed_verbs = 'open,close,hold,put,take,throw,grasp,turn,tidy,eat,wash,pour,drink,walk,stand,run,sit,lie,watch'.split(',')\n",
    "conditions = action_data['verb'].isin(allowed_verbs)\n",
    "action_data = action_data[conditions]\n",
    "\n",
    "action_full_data = action_data\n",
    "#---------------------------------------------\n",
    "# TODO: seprate target verbs and condition verbs\n",
    "\n",
    "condition_verb = 'open,close,hold,put,take,throw,grasp,turn,tidy,eat,wash,pour,drink,walk,stand,run,sit,lie,watch'.split(',')\n",
    "conditions = action_data['verb'].isin(condition_verb)\n",
    "condition_action_data = action_data[conditions]\n",
    "\n",
    "# filtering target verbs by composition statistics\n",
    "def generate_voc_by_composition(action_data):\n",
    "    ## object classes statistics by verbs\n",
    "    obj_classes_by_verb = action_data.groupby('verb')['object'].nunique()\n",
    "    cleaned_verb_voc = obj_classes_by_verb[obj_classes_by_verb > 1] #.count()\n",
    "    # cleaned_verb_voc\n",
    "\n",
    "    ## verb classes statistics by objects\n",
    "    tmp_action_data = action_data[action_data['verb'].isin(cleaned_verb_voc.keys())] # .notnull()\n",
    "    verb_classes_by_obj = tmp_action_data.groupby('object')['verb'].nunique()\n",
    "#     verb_classes_by_obj.pop('None')\n",
    "    # print(verb_classes_by_obj)\n",
    "    cleaned_obj_voc = verb_classes_by_obj[ (verb_classes_by_obj > 1) ] #.count()\n",
    "    return cleaned_verb_voc, cleaned_obj_voc\n",
    "\n",
    "cleaned_verb_voc, cleaned_obj_voc = generate_voc_by_composition(action_data)\n",
    "\n",
    "del cleaned_obj_voc['vacuum']\n",
    "\n",
    "action_data = action_data[action_data['verb'].isin(cleaned_verb_voc.keys())]\n",
    "action_data = action_data[action_data['object'].isin(cleaned_obj_voc.keys())]\n",
    "\n",
    "print('final vocabulary:')\n",
    "print('cleaned_verb_voc',len(cleaned_verb_voc.keys()), '\\t', ', '.join(cleaned_verb_voc.keys()))\n",
    "print('cleaned_obj_voc',len(cleaned_obj_voc.keys()), '\\t', ', '.join(cleaned_obj_voc.keys()))\n",
    "\n",
    "keep_action_ids = action_data['action_id'].unique()\n",
    "unwanted = set(act_map.keys()) - set(keep_action_ids)\n",
    "# list(map(verb_map.pop, unwanted))\n",
    "# list(map(obj_map.pop, unwanted))\n",
    "# list(map(act_map.pop, unwanted))\n",
    "print('cleaned_act_voc',len(act_map.keys()))\n",
    "\n",
    "#---------------------------------------------\n",
    "# TODO: seprate target verbs and condition verbs\n",
    "target_verb =    'open,close,hold,put,take,throw,grasp,tidy,eat,wash,pour,drink,walk,sit,lie'.split(',')\n",
    "conditions = action_data['verb'].isin(target_verb)\n",
    "action_data = action_data[conditions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list=list(set(action_full_data['verb']))\n",
    "obj_list = list(set(action_full_data['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add action columns to video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add ordered data by action_full_data\n",
    "video_data['ordered_action_ids'] = action_full_data.groupby(level=0).agg(','.join)['action_id']\n",
    "video_data['verbs'] = video_data['ordered_action_ids'].str.strip().replace(verb_map, regex=True)\n",
    "video_data['objs'] = video_data['ordered_action_ids'].str.strip().replace(obj_map, regex=True)\n",
    "video_data['action_words'] = video_data['ordered_action_ids'].str.strip().replace(act_map, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add controled_action_words\n",
    "video_data['controled_action_ids'] = action_data.groupby(level=0).agg(','.join)['action_id']\n",
    "video_data['controled_action_words'] = video_data['controled_action_ids'].str.strip().replace(act_map, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "# Clean video_data \n",
    "processed_video_data = filter_video_samples(video_data)\n",
    "processed_video_data = processed_video_data.dropna()\n",
    "processed_video_data_fea = copy.deepcopy(processed_video_data)\n",
    "\n",
    "eliminated_video_ids = 'T5ECU,AAH6R,AF8I2,GL2JW,YSE1G,L3ZRP,T56KO,SBI6Z,1FX8Q,3SKWW,YN3AA,C10FA,OZIJ7,DV31C,TANB8,MUK89,BLWIW,R5L98'.split(',') \n",
    "mp_vid = json.load(open(multi_person_vid))\n",
    "eliminated_video_ids = eliminated_video_ids+mp_vid\n",
    "processed_video_data = processed_video_data[ ~processed_video_data['id'].isin(eliminated_video_ids) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use extract_action_dict to filter action_ids in QA generation\n",
    "processed_action_dict = extract_action_dict(processed_video_data, verb_map, obj_map,action_data)\n",
    "processed_condition_action_dict = extract_action_dict(processed_video_data, verb_map, obj_map,condition_action_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated_video_ids = 'T5ECU,AAH6R,AF8I2,GL2JW,YSE1G,L3ZRP,T56KO,SBI6Z,1FX8Q,3SKWW,YN3AA,C10FA,BLWIW,WTJQ0,9FH1E'.split(',') \n",
    "eliminated_video_ids = eliminated_video_ids + mp_vid\n",
    "processed_video_data_fea = processed_video_data_fea[ ~processed_video_data_fea['id'].isin(eliminated_video_ids) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_action_dict_fea = extract_action_dict(processed_video_data_fea, verb_map, obj_map,action_data)\n",
    "processed_condition_action_dict_fea = extract_action_dict(processed_video_data_fea, verb_map, obj_map,condition_action_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(action_data[(action_data['verb'] == 'eat')]['object'])-set(['book']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. QA Template and Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CHECK: separate target and condition action\n",
    "qa_templates = {}\n",
    "def QAGeneration(QAGenerator, processed_action_dict, processed_condition_action_dict, avoid, qtype, template,option_generation, **kwargs):\n",
    "    QAList = []\n",
    "    question_idx = 0\n",
    "    qa_generators = {}\n",
    "    \n",
    "    qa_generators[\"Interaction\"] = [interaction_t1, interaction_t2, interaction_t3, interaction_t4]\n",
    "    qa_generators[\"Sequence\"] = [sequence_t1, sequence_t2, sequence_t3, sequence_t4, sequence_t5,sequence_t6] \n",
    "    qa_generators[\"Prediction\"] = [prediction_t1, prediction_t2, prediction_t3, prediction_t4]\n",
    "    qa_generators[\"Feasibility\"] = [feasibility_t1, feasibility_t2, feasibility_t3, feasibility_t4, feasibility_t5,feasibility_t6]\n",
    "    \n",
    "    for video_id in processed_action_dict.keys():\n",
    "        if not anno_video_split.__contains__(video_id):\n",
    "            continue\n",
    "        # all actions\n",
    "        action_list = processed_action_dict[video_id][0]  \n",
    "        # denoise action lsit\n",
    "        if qtype!='Feasibility':\n",
    "            action_list = denoise(action_list,verb_map,obj_map,**kwargs)\n",
    "        if video_id not in processed_condition_action_dict.keys():\n",
    "            continue\n",
    "        condition_action_list = processed_condition_action_dict[video_id][0]\n",
    "        template_id = '{}_T{}'.format(qtype, str(template))\n",
    "        QAList, question_idx, Question, Answer = qa_generators[qtype][template-1](QAGenerator, template_id, QAList, action_list, condition_action_list, question_idx, video_id,option_generation) \n",
    "    #print(len(QAList))\n",
    "    question_type = qtype +'_T' +str(template)\n",
    "    if qtype not in qa_templates:\n",
    "            qa_templates[qtype] = {}\n",
    "    qa_templates[qtype][template-1] = {'question': Question, 'answer': Answer}\n",
    "    \n",
    "    if len(QAList) > 0:\n",
    "        print('TID:', template_id, ', Last QID:', ('_').join([template_id, str(question_idx)]))\n",
    "    else:\n",
    "        print('len(QAList) == 0')\n",
    "    \n",
    "    return QAList, question_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwargs = {'max_time': 10.0, 'min_time': -1, 'max_action_id': 145,\n",
    "          'eliminated_action_id': [], #''.split(','),\n",
    "          'specific_verb': ['hold'],\n",
    "          'specific_obj': ['None'],\n",
    "         } \n",
    "avoid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output QA Data\n",
    "save_qa_json = True\n",
    "save_shuffle = False\n",
    "show_shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_answer_frequence = None\n",
    "train_answer_space = None\n",
    "generator = QAGenerator(processed_action_dict, anno_video_split, \n",
    "                    act_map, obj_map, verb_map, action_data, fps,\n",
    "                    extend_sg, sg,\n",
    "                    train_answer_space,train_answer_frequence)\n",
    "option_generation=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_dict = {'Interaction':[1,2,3,4],\n",
    "'Sequence':[1,2,3,4,5,6],\n",
    "'Prediction':[1,2,3,4],\n",
    "'Feasibility':[1,2,3,4,5,6]}\n",
    "feasibility_filer_dict = {1:compositional_obj_feasibility,\n",
    "2:compositional_verb_feasibility,3:spatial_feasibitity,4:spatial_feasibitity,\n",
    "5:temporal_feasibitity,6:temporal_feasibitity}\n",
    "\n",
    "for qtype in generation_dict:\n",
    "    for temp in generation_dict[qtype]:\n",
    "        if qtype=='Feasibility':\n",
    "            processed_action_dict_fea_,processed_condition_action_dict_fea_ = feasibility_filer_dict[temp](processed_video_data_fea,verb_map, obj_map,action_data, condition_action_data,cleaned_obj_voc)\n",
    "            QAList, _ = QAGeneration(generator, processed_action_dict_fea_,processed_condition_action_dict_fea_, avoid, qtype, temp,option_generation, **kwargs)\n",
    "        else:    \n",
    "            QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, avoid, qtype, temp,option_generation, **kwargs)\n",
    "        \n",
    "        save_qa_data(QAList, qtype, temp,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split and Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtypes = ['Interaction','Sequence','Prediction','Feasibility']\n",
    "all_qa = []\n",
    "for key in qtypes:\n",
    "    all_qa.extend(load_all_json_in_folder(save_data_dir + key + '/'))\n",
    "all_qa_meta = extract_qa_meta(all_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa_unsampled, val_qa_unsampled, test_qa_unsampled = split_dataset(all_qa_meta,1,False,0.6,0.2,0.2)\n",
    "train_ans_space = get_answer_space(train_qa_unsampled,'../annotations/generation_annotations/train_answer_space.json')\n",
    "train_fre_space = get_answer_frequency(train_qa_unsampled,'../annotations/generation_annotations/train_answer_frequence.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_dict = {'train':{},'val':{},'test':{}}\n",
    "input_dict = {'train':train_qa_unsampled,'val':val_qa_unsampled,'test':test_qa_unsampled}\n",
    "for d in input_dict:\n",
    "    interaction, sequence ,prediction ,feasibility = split_by_qtype(input_dict[d])\n",
    "    biased_dict[d]['Interaction']= interaction\n",
    "    biased_dict[d]['Sequence']= sequence\n",
    "    biased_dict[d]['Prediction']= prediction\n",
    "    biased_dict[d]['Feasibility']= feasibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debised_dict = {'train':{},'val':{},'test':{}}\n",
    "for d in debised_dict:\n",
    "    for q in qtypes:\n",
    "        debised_dict[d][q]= QA_postprocess(biased_dict[d][q],0.25,0.95,d,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id, val_id, test_id = [], [], []\n",
    "for q in debised_dict['train']:\n",
    "    train_id.extend(debised_dict['train'][q])\n",
    "for q in debised_dict['val']:\n",
    "    val_id.extend(debised_dict['val'][q])\n",
    "for q in debised_dict['test']:\n",
    "    test_id.extend(debised_dict['test'][q])\n",
    "train_id = [qa['question_id'] for qa in train_id]\n",
    "val_id = [qa['question_id'] for qa in val_id]\n",
    "test_id = [qa['question_id'] for qa in test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(train_id,'../annotations/generation_annotations/train_id.json')\n",
    "write_json(val_id,'../annotations/generation_annotations/val_id.json')\n",
    "write_json(test_id,'../annotations/generation_annotations/test_id.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. QA Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_generation=True\n",
    "train_answer_frequence = json.load(open(annotation_dir+'/train_answer_frequence.json'))\n",
    "train_answer_space = json.load(open(annotation_dir+'/train_answer_space.json'))\n",
    "generator = QAGenerator(processed_action_dict, anno_video_split, \n",
    "                    act_map, obj_map, verb_map, action_data, fps,\n",
    "                    extend_sg, sg,\n",
    "                    train_answer_space,train_answer_frequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Interaction'\n",
    "template=1\n",
    "selected_video_ids  = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids,show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction T2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Interaction'\n",
    "template=2\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids,show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Interaction'\n",
    "template=3\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids,show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Interaction'\n",
    "template=4\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids,show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Sequence'\n",
    "template=1\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence T2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "qtype='Sequence'\n",
    "template=2\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence T3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "qtype='Sequence'\n",
    "template=3\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence T4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Sequence'\n",
    "template=4\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence T5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "qtype='Sequence'\n",
    "template=5\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence T6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Sequence'\n",
    "template=6\n",
    "selected_video_ids = []\n",
    "\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Prediction'\n",
    "template=1\n",
    "selected_video_ids = []\n",
    "\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[0:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Prediction'\n",
    "template=2\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Prediction'\n",
    "template=3\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Prediction'\n",
    "template=4\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict,processed_condition_action_dict, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "processed_action_dict_fea_,processed_condition_action_dict_fea_ = compositional_obj_feasibility(processed_video_data_fea,verb_map, obj_map,action_data, condition_action_data,cleaned_obj_voc)\n",
    "qtype='Feasibility'\n",
    "template=1\n",
    "\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict_fea_,processed_condition_action_dict_fea_, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "processed_action_dict_fea_,processed_condition_action_dict_fea_ = compositional_verb_feasibility(processed_video_data_fea,verb_map, obj_map,action_data, condition_action_data,cleaned_obj_voc)\n",
    "qtype='Feasibility'\n",
    "template=2\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict_fea_,processed_condition_action_dict_fea_, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "processed_action_dict_fea_,processed_condition_action_dict_fea_ = spatial_feasibitity(processed_video_data_fea,verb_map, obj_map,action_data, condition_action_data,cleaned_obj_voc)\n",
    "qtype='Feasibility'\n",
    "template=3\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict_fea_,processed_condition_action_dict_fea_, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Feasibility'\n",
    "template=4\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict_fea_,processed_condition_action_dict_fea_, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "processed_action_dict_fea_,processed_condition_action_dict_fea_ = temporal_feasibitity(processed_video_data_fea,verb_map, obj_map,action_data, condition_action_data,cleaned_obj_voc)\n",
    "qtype='Feasibility'\n",
    "template=5\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict_fea_,processed_condition_action_dict_fea_, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility T6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qtype='Feasibility'\n",
    "template=6\n",
    "selected_video_ids = []\n",
    "# generate\n",
    "QAList, _ = QAGeneration(generator, processed_action_dict_fea_,processed_condition_action_dict_fea_, \n",
    "                         avoid,qtype, template,option_generation, **kwargs)\n",
    "print('generated', len(QAList))\n",
    "# post processing for demo\n",
    "QAList_demo = demo_postprocess(QAList, selected_video_ids, show_shuffle)\n",
    "# visulization for quanlity checking\n",
    "@interact\n",
    "def show_examples(question_idx = range(0, len(QAList_demo[:100]))):   \n",
    "    temp_qa_visulization([QAList_demo[:100][question_idx]], video_dir ,save_dir) \n",
    "    \n",
    "# save output\n",
    "save_qa_data(QAList, qtype, template,save_data_dir,save_qa_json,save_shuffle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
