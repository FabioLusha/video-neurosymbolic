{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import STAR_utils.visualization_tools.qa_visualization as qaviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../data/datasets/STAR/STAR_val.json\") as in_file:\n",
    "    star_data = json.load(in_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_id',\n",
       " 'question',\n",
       " 'video_id',\n",
       " 'start',\n",
       " 'end',\n",
       " 'answer',\n",
       " 'question_program',\n",
       " 'choices',\n",
       " 'situations']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = 101\n",
    "test_sample = star_data[test_id]\n",
    "list(test_sample.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000153': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[90.05, 176.79, 103.43, 190.5],\n",
       "   [91.62, 176.57, 103.16, 190.42],\n",
       "   [64.53, 140.75, 124.1, 348.32]],\n",
       "  'bbox_labels': ['o028', 'o016', 'o000']},\n",
       " '000188': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r004', 'r003', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[121.69, 171.11, 133.14, 184.65],\n",
       "   [134.26, 158.83, 140.57, 166.44],\n",
       "   [122.52, 169.68, 135.62, 184.51],\n",
       "   [78.95, 137.09, 153.44, 337.95]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']},\n",
       " '000159': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r004', 'r003', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[99.8, 175.01, 114.15, 190.01],\n",
       "   [111.95, 159.77, 116.7, 168.77],\n",
       "   [101.78, 175.7, 113.96, 189.18],\n",
       "   [71.88, 138.0, 132.37, 342.93]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']},\n",
       " '000222': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r003', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[123.49, 165.73, 137.15, 180.73],\n",
       "   [133.37, 154.35, 138.96, 162.29],\n",
       "   [124.57, 167.31, 136.9, 181.48],\n",
       "   [90.76, 121.57, 155.5, 363.92]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']},\n",
       " '000246': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r003', 'r004', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[128.81, 190.31, 143.62, 208.27],\n",
       "   [141.55, 158.96, 152.01, 167.15],\n",
       "   [129.18, 189.34, 142.87, 209.34],\n",
       "   [86.91, 131.32, 166.18, 362.53]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']},\n",
       " '000217': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[124.01, 165.81, 138.14, 180.81],\n",
       "   [125.67, 165.91, 136.51, 181.13],\n",
       "   [91.83, 124.6, 156.7, 352.0]],\n",
       "  'bbox_labels': ['o028', 'o016', 'o000']},\n",
       " '000239': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r004', 'r003', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[119.44, 176.63, 135.72, 194.1],\n",
       "   [132.27, 153.79, 137.98, 165.22],\n",
       "   [120.97, 176.83, 134.44, 193.94],\n",
       "   [82.88, 128.18, 156.06, 346.72]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']},\n",
       " '000256': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r005', 'r009', 'r002', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[138.55, 191.49, 155.72, 210.32],\n",
       "   [161.85, 155.55, 168.22, 166.46],\n",
       "   [138.29, 190.72, 156.1, 211.65],\n",
       "   [103.81, 125.52, 185.41, 381.21]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']},\n",
       " '000291': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r003', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[126.05, 193.86, 148.36, 220.59],\n",
       "   [156.0, 152.89, 163.92, 165.39],\n",
       "   [125.01, 194.05, 148.76, 219.88],\n",
       "   [79.86, 111.34, 185.25, 437.38]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']},\n",
       " '000275': {'rel_pairs': [['o000', 'o028'],\n",
       "   ['o000', 'o028'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o014'],\n",
       "   ['o000', 'o016'],\n",
       "   ['o000', 'o016']],\n",
       "  'rel_labels': ['r009', 'r002', 'r009', 'r003', 'r009', 'r002'],\n",
       "  'actions': ['a051'],\n",
       "  'bbox': [[128.12, 191.05, 149.66, 214.7],\n",
       "   [151.86, 151.7, 160.95, 163.52],\n",
       "   [127.81, 191.54, 148.03, 214.15],\n",
       "   [86.02, 115.31, 183.07, 428.86]],\n",
       "  'bbox_labels': ['o028', 'o014', 'o016', 'o000']}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample['situations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000153': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000188': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r004', 'o014'),\n",
       "  ('o000', 'r003', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000159': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r004', 'o014'),\n",
       "  ('o000', 'r003', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000222': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r003', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000246': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r003', 'o014'),\n",
       "  ('o000', 'r004', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000217': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000239': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r004', 'o014'),\n",
       "  ('o000', 'r003', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000256': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r005', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r002', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000291': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r003', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')],\n",
       " '000275': [('o000', 'r009', 'o028'),\n",
       "  ('o000', 'r002', 'o028'),\n",
       "  ('o000', 'r009', 'o014'),\n",
       "  ('o000', 'r003', 'o014'),\n",
       "  ('o000', 'r009', 'o016'),\n",
       "  ('o000', 'r002', 'o016')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dict = dict()\n",
    "\n",
    "for frame_id, frame_info in test_sample['situations'].items():\n",
    "    graph_dict[frame_id] = []\n",
    "    for i in range(len(frame_info['rel_pairs'])):\n",
    "\n",
    "        assert len(frame_info['rel_pairs']) == len(frame_info['rel_labels'])\n",
    "        \n",
    "        entry = (frame_info['rel_pairs'][i][0], frame_info['rel_labels'][i], frame_info['rel_pairs'][i][1])\n",
    "        graph_dict[frame_id].append(entry)\n",
    "\n",
    "graph_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tQ: Which object was eaten by the person? \n",
      "\n",
      "\tAnswer: The sandwich.\n",
      "\tOption: The medicine.\n",
      "\tOption: The clothes.\n",
      "\tOption: The window.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qaviz.Vis_Question_Answer_Options(test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Frame ID: 000153\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "1 Frame ID: 000159\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  above  ----  phone/camera\n",
      "\t\t person  ----  on_the_side_of  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "2 Frame ID: 000188\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  above  ----  phone/camera\n",
      "\t\t person  ----  on_the_side_of  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "3 Frame ID: 000217\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "4 Frame ID: 000222\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  on_the_side_of  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "5 Frame ID: 000239\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  above  ----  phone/camera\n",
      "\t\t person  ----  on_the_side_of  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "6 Frame ID: 000246\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  on_the_side_of  ----  phone/camera\n",
      "\t\t person  ----  above  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "7 Frame ID: 000256\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  beneath  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  in_front_of  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "8 Frame ID: 000275\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  on_the_side_of  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n",
      "9 Frame ID: 000291\n",
      "Subgraph:\n",
      "\t Actions:\n",
      "\t\t eat a sandwich\n",
      "\t Relationships:\n",
      "\t\t person  ----  holding  ----  food\n",
      "\t\t person  ----  in_front_of  ----  food\n",
      "\t\t person  ----  holding  ----  phone/camera\n",
      "\t\t person  ----  on_the_side_of  ----  phone/camera\n",
      "\t\t person  ----  holding  ----  sandwich\n",
      "\t\t person  ----  in_front_of  ----  sandwich\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qaviz.Vis_SituationGraph(test_sample, 1_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
