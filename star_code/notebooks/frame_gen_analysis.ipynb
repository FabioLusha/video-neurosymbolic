{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "import os, sys, pathlib\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import importlib\n",
    "\n",
    "BASE_DIR = pathlib.Path.cwd().parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(BASE_DIR / 'src'))\n",
    "\n",
    "import ollama_manager as om\n",
    "import main\n",
    "import STAR_utils.visualization_tools.qa_visualization as qaviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please replace following data path to your local path\n",
    "# all data can be download from our homepages (http://star.csail.mit.edu or https://bobbywu.com/STAR)\n",
    "\n",
    "# root_dir = '/root/user/'\n",
    "raw_video_dir = BASE_DIR / 'data/datasets/action-genome/Charades_v1_480/'\n",
    "raw_frame_dir = BASE_DIR / 'data/datasets/action-genome/frames/'\n",
    "annotation_dir = BASE_DIR / 'src/STAR_utils/annotations/STAR_classes/'\n",
    "# pose_dir = root_dir + 'STAR/pose/'\n",
    "# qa_train_dir = BASE_DIR /'data/datasets/STAR/STAR_annotations/STAR_train.json' \n",
    "qa_val_data = BASE_DIR / 'data/datasets/STAR/STAR_annotations/STAR_val.json' \n",
    "# qa_test_dir = BASE_DIR / 'data/datasets/STAR/STAR_annotations/STAR_test.json' \n",
    "save_video_dir = BASE_DIR / 'visualization_tmp'\n",
    "fps = pickle.load(open(annotation_dir / 'video_fps','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data = []\n",
    "with open(qa_val_data, 'r') as f:\n",
    "    star_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>video_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_program</th>\n",
       "      <th>choices</th>\n",
       "      <th>situations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Interaction_T1_13</th>\n",
       "      <td>Which object was tidied up by the person?</td>\n",
       "      <td>6H78U</td>\n",
       "      <td>11.1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>The clothes.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'The closet/cabine...</td>\n",
       "      <td>{'000206': {'rel_pairs': [['o000', 'o027'], ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction_T1_14</th>\n",
       "      <td>Which object was tidied up by the person?</td>\n",
       "      <td>6H78U</td>\n",
       "      <td>15.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>The clothes.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'The blanket.', 'c...</td>\n",
       "      <td>{'000289': {'rel_pairs': [['o000', 'o027'], ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction_T1_31</th>\n",
       "      <td>Which object was thrown by the person?</td>\n",
       "      <td>RNLTR</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>The clothes.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'The pillow.', 'ch...</td>\n",
       "      <td>{'000132': {'rel_pairs': [['o000', 'o019'], ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction_T1_32</th>\n",
       "      <td>Which object was put down by the person?</td>\n",
       "      <td>RNLTR</td>\n",
       "      <td>11.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>The shoe.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'The food.', 'choi...</td>\n",
       "      <td>{'000202': {'rel_pairs': [['o000', 'o019'], ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interaction_T1_40</th>\n",
       "      <td>Which object was tidied up by the person?</td>\n",
       "      <td>VNQTH</td>\n",
       "      <td>2.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>The closet/cabinet.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'The broom.', 'cho...</td>\n",
       "      <td>{'000110': {'rel_pairs': [['o000', 'o014'], ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feasibility_T6_1453</th>\n",
       "      <td>What is the person able to do after taking the...</td>\n",
       "      <td>L9ANI</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>Wash the table.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'Wash the table.',...</td>\n",
       "      <td>{'000227': {'rel_pairs': [['o000', 'o006'], ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feasibility_T6_1454</th>\n",
       "      <td>What is the person able to do after walking th...</td>\n",
       "      <td>L9ANI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Take the towel.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'Take the towel.',...</td>\n",
       "      <td>{'000033': {'rel_pairs': [['o000', 'o006']], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feasibility_T6_1455</th>\n",
       "      <td>What is the person able to do after walking th...</td>\n",
       "      <td>L9ANI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Wash the table.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'Throw the bag.', ...</td>\n",
       "      <td>{'000033': {'rel_pairs': [['o000', 'o006']], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feasibility_T6_1456</th>\n",
       "      <td>What is the person able to do after putting th...</td>\n",
       "      <td>L9ANI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>Wash the table.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'Hold the food.', ...</td>\n",
       "      <td>{'000033': {'rel_pairs': [['o000', 'o006']], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feasibility_T6_1468</th>\n",
       "      <td>What is the person able to do after opening th...</td>\n",
       "      <td>Z97SD</td>\n",
       "      <td>18.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>Hold the food.</td>\n",
       "      <td>[{'function': 'Situations', 'value_input': []}...</td>\n",
       "      <td>[{'choice_id': 0, 'choice': 'Wash the window.'...</td>\n",
       "      <td>{'000588': {'rel_pairs': [['o000', 'o008']], '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7098 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              question  \\\n",
       "question_id                                                              \n",
       "Interaction_T1_13            Which object was tidied up by the person?   \n",
       "Interaction_T1_14            Which object was tidied up by the person?   \n",
       "Interaction_T1_31               Which object was thrown by the person?   \n",
       "Interaction_T1_32             Which object was put down by the person?   \n",
       "Interaction_T1_40            Which object was tidied up by the person?   \n",
       "...                                                                ...   \n",
       "Feasibility_T6_1453  What is the person able to do after taking the...   \n",
       "Feasibility_T6_1454  What is the person able to do after walking th...   \n",
       "Feasibility_T6_1455  What is the person able to do after walking th...   \n",
       "Feasibility_T6_1456  What is the person able to do after putting th...   \n",
       "Feasibility_T6_1468  What is the person able to do after opening th...   \n",
       "\n",
       "                    video_id  start   end               answer  \\\n",
       "question_id                                                      \n",
       "Interaction_T1_13      6H78U   11.1  19.6         The clothes.   \n",
       "Interaction_T1_14      6H78U   15.6  22.7         The clothes.   \n",
       "Interaction_T1_31      RNLTR    7.3  13.5         The clothes.   \n",
       "Interaction_T1_32      RNLTR   11.6  16.4            The shoe.   \n",
       "Interaction_T1_40      VNQTH    2.7   9.2  The closet/cabinet.   \n",
       "...                      ...    ...   ...                  ...   \n",
       "Feasibility_T6_1453    L9ANI    7.3  12.9      Wash the table.   \n",
       "Feasibility_T6_1454    L9ANI    0.0   4.1      Take the towel.   \n",
       "Feasibility_T6_1455    L9ANI    0.0   4.1      Wash the table.   \n",
       "Feasibility_T6_1456    L9ANI    0.0  10.8      Wash the table.   \n",
       "Feasibility_T6_1468    Z97SD   18.1  24.1       Hold the food.   \n",
       "\n",
       "                                                      question_program  \\\n",
       "question_id                                                              \n",
       "Interaction_T1_13    [{'function': 'Situations', 'value_input': []}...   \n",
       "Interaction_T1_14    [{'function': 'Situations', 'value_input': []}...   \n",
       "Interaction_T1_31    [{'function': 'Situations', 'value_input': []}...   \n",
       "Interaction_T1_32    [{'function': 'Situations', 'value_input': []}...   \n",
       "Interaction_T1_40    [{'function': 'Situations', 'value_input': []}...   \n",
       "...                                                                ...   \n",
       "Feasibility_T6_1453  [{'function': 'Situations', 'value_input': []}...   \n",
       "Feasibility_T6_1454  [{'function': 'Situations', 'value_input': []}...   \n",
       "Feasibility_T6_1455  [{'function': 'Situations', 'value_input': []}...   \n",
       "Feasibility_T6_1456  [{'function': 'Situations', 'value_input': []}...   \n",
       "Feasibility_T6_1468  [{'function': 'Situations', 'value_input': []}...   \n",
       "\n",
       "                                                               choices  \\\n",
       "question_id                                                              \n",
       "Interaction_T1_13    [{'choice_id': 0, 'choice': 'The closet/cabine...   \n",
       "Interaction_T1_14    [{'choice_id': 0, 'choice': 'The blanket.', 'c...   \n",
       "Interaction_T1_31    [{'choice_id': 0, 'choice': 'The pillow.', 'ch...   \n",
       "Interaction_T1_32    [{'choice_id': 0, 'choice': 'The food.', 'choi...   \n",
       "Interaction_T1_40    [{'choice_id': 0, 'choice': 'The broom.', 'cho...   \n",
       "...                                                                ...   \n",
       "Feasibility_T6_1453  [{'choice_id': 0, 'choice': 'Wash the table.',...   \n",
       "Feasibility_T6_1454  [{'choice_id': 0, 'choice': 'Take the towel.',...   \n",
       "Feasibility_T6_1455  [{'choice_id': 0, 'choice': 'Throw the bag.', ...   \n",
       "Feasibility_T6_1456  [{'choice_id': 0, 'choice': 'Hold the food.', ...   \n",
       "Feasibility_T6_1468  [{'choice_id': 0, 'choice': 'Wash the window.'...   \n",
       "\n",
       "                                                            situations  \n",
       "question_id                                                             \n",
       "Interaction_T1_13    {'000206': {'rel_pairs': [['o000', 'o027'], ['...  \n",
       "Interaction_T1_14    {'000289': {'rel_pairs': [['o000', 'o027'], ['...  \n",
       "Interaction_T1_31    {'000132': {'rel_pairs': [['o000', 'o019'], ['...  \n",
       "Interaction_T1_32    {'000202': {'rel_pairs': [['o000', 'o019'], ['...  \n",
       "Interaction_T1_40    {'000110': {'rel_pairs': [['o000', 'o014'], ['...  \n",
       "...                                                                ...  \n",
       "Feasibility_T6_1453  {'000227': {'rel_pairs': [['o000', 'o006'], ['...  \n",
       "Feasibility_T6_1454  {'000033': {'rel_pairs': [['o000', 'o006']], '...  \n",
       "Feasibility_T6_1455  {'000033': {'rel_pairs': [['o000', 'o006']], '...  \n",
       "Feasibility_T6_1456  {'000033': {'rel_pairs': [['o000', 'o006']], '...  \n",
       "Feasibility_T6_1468  {'000588': {'rel_pairs': [['o000', 'o008']], '...  \n",
       "\n",
       "[7098 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_df = pd.DataFrame(star_data)\n",
    "star_df = star_df.set_index('question_id')\n",
    "star_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000286',\n",
       " '000289',\n",
       " '000294',\n",
       " '000301',\n",
       " '000303',\n",
       " '000308',\n",
       " '000313',\n",
       " '000314',\n",
       " '000316',\n",
       " '000318',\n",
       " '000320',\n",
       " '000322',\n",
       " '000331',\n",
       " '000332',\n",
       " '000336',\n",
       " '000337',\n",
       " '000339',\n",
       " '000364',\n",
       " '000370',\n",
       " '000377',\n",
       " '000388',\n",
       " '000389',\n",
       " '000392']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(star_df.loc['Interaction_T1_14']['situations'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "\n",
    "SEED = 712407852679\n",
    "\n",
    "url = os.environ.get(\"OLLAMA_URL\", \"http://lusha_ollama:11435\")\n",
    "\n",
    "sys_prompt = main._load_prompt_fromfile(\n",
    "        BASE_DIR / \"data/prompts/zero-shot-cot/MCQ_system_prompt_ZS_CoT.txt\"\n",
    "    )\n",
    "\n",
    "ollama_params={\n",
    "            \"model\": \"gemma3:4b\",\n",
    "            \"system\": None,\n",
    "            \"stream\": True,\n",
    "            \"options\": {\n",
    "                \"num_ctx\": 10240,\n",
    "                \"temperature\": 0.1,\n",
    "                \"num_predict\": 1024,\n",
    "                \"seed\": SEED,\n",
    "            },\n",
    "        }\n",
    "\n",
    "client = om.OllamaRequestManager(url, ollama_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'main' from '/home/lusha/star_code/src/main.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses will be saved to: /home/lusha/star_code/test_o.jsonl\n",
      "Errors will be logged to: outputs/errors_20250430_20:42:31.txt\n",
      "========================= Starting Response Generation =========================\n",
      "\n",
      "Generating response for iteration 1 - id: Interaction_T1_13\n",
      "Okay, let's analyze the images and answer the question.\n",
      "\n",
      "**Image Description & Analysis:**\n",
      "\n",
      "1.  **Image 1:** A man is standing in a room with a large, somewhat worn brown sofa. An air conditioning unit is mounted on the wall. He is looking at the sofa.\n",
      "2.  **Image 2:** The man is now kneeling and using a green cleaning tool (likely a brush or sponge) to clean a stain or dirt on the sofa.\n",
      "3.  **Image 3:** The man is still kneeling, continuing to clean the sofa with the green tool.\n",
      "4.  **Image 4:** The man is standing up, having finished cleaning the sofa.\n",
      "5.  **Image 5:** The man is standing, holding the green cleaning tool.\n",
      "6.  **Image 6:** The man is standing, holding the green cleaning tool.\n",
      "7.  **Image 7:** The man is standing, holding the green cleaning tool.\n",
      "8.  **Image 8:** The man is standing, holding the green cleaning tool.\n",
      "9.  **Image 9:** The man is standing, holding the green cleaning tool.\n",
      "\n",
      "**Inference & Answer:**\n",
      "\n",
      "Based on the sequence of images, the man is cleaning a stain or dirt on the sofa. The object he is using to do this is the green cleaning tool.\n",
      "\n",
      "Therefore, the answer is **B. The blanket.**\n",
      "\n",
      "Response at: 7.5 tk/s\n",
      "```json\n",
      "{\"answer\": \"B. The blanket\"}\n",
      "```\n",
      "\n",
      "Response at: 7.8 tk/s\n"
     ]
    }
   ],
   "source": [
    "import prompt_formatters as pf\n",
    "\n",
    "user_prompt = '''\\\n",
    "You will receive a sequence of images and a question related to them. Analyze the images in the order they are presented,\\\n",
    "extract relevant details, and identify any patterns, changes, or relationships between them. Use this information to provide\\\n",
    "a choose one of the presented alternatives\n",
    "\n",
    "Instructions:\n",
    "- Describe each image in the sequence briefly but meaningfully.\n",
    "- Note any important transitions or developments between consecutive images.\n",
    "- Combine observations to infer the overall context or narrative.\n",
    "- Answer the question based on your analysis, ensuring your response is grounded in the visual evidence.\n",
    "- Read the question and reason about the answer step by step.\n",
    "- In your answer include key events or relationships that help you in determine the correct answer.\n",
    "- Be careful to reproduce the chosen alternative as it is presented.\n",
    "\n",
    "Q: {question}\n",
    "<Alternatives>\n",
    "A. {c1}\n",
    "B. {c2}\n",
    "C. {c3}\n",
    "D. {c4}\n",
    "</Alternatives>\\\n",
    "'''\n",
    "\n",
    "mcq_pformatter = pf.MCQPromptWoutSTSG(user_prompt)\n",
    "input_filepath = BASE_DIR / \"data/datasets/STAR_QA_and_stsg_val.json\"  # Default to MCQ\n",
    "\n",
    "ids = ['Interaction_T1_13']\n",
    "\n",
    "dataset = om.PromptDataset(input_filepath, mcq_pformatter, ids=ids)\n",
    "prompts = [dataset[i] for i in range(len(dataset))]\n",
    "\n",
    "reply = \"\"\"\\\n",
    "Therefore the final answer is?\n",
    "\n",
    "Your response must be provided in valid JSON format as follows:\n",
    "{\"answer\": \"your complete answer here\"}\n",
    "\n",
    "IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\n",
    "Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \n",
    "should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.\\\n",
    "\"\"\"\n",
    "\n",
    "main.stream_vqa(client, prompts, ids, reply, output_filepath=BASE_DIR / \"test_o.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qid': 'Interaction_T2_3150',\n",
       "  'chat_history': [{'role': 'user',\n",
       "    'content': 'Please carefully read the following Spatio-Temporal Scene Graph delimited by the <STSG> tags and provide an answer to the question below:\\n\\n<STSG>\\n\\nFrame 000019:\\n\\nwoman ---- lying_on ---- bed\\nbed ---- containing ---- sheets\\nsheets ---- covering ---- mattress\\nbed ---- adjacent_to ---- bedside_table\\nbedside_table ---- supporting ---- lamp\\nlamp ---- having_shade ---- lampshade\\nlampshade ---- above ---- book\\nbook ---- on_top_of ---- bedside_table\\nbed ---- adjacent_to ---- wall\\nwall ---- supporting ---- curtains\\ncurtains ---- hanging_on ---- wall\\nbed ---- on_top_of ---- floor\\nfloor ---- dark_color\\nbed ---- adjacent_to ---- woman\\nwoman ---- lying_on ---- bed\\n\\nFrame 000054:\\n\\nwoman ---- lying_on ---- bed\\nbed ---- containing ---- woman\\nbed ---- supporting ---- pillow\\npillow ---- under ---- woman\\nbed ---- adjacent_to ---- nightstand\\nnightstand ---- holding ---- lamp\\nlamp ---- emitting_light_on ---- nightstand\\nnightstand ---- holding ---- books\\nbooks ---- stacked_on ---- nightstand\\nbed ---- against ---- wall\\nwall ---- supporting ---- bed\\nbed ---- adjacent_to ---- bookcase\\nbookcase ---- in_background ---- room\\nbed ---- on ---- floor\\nbed ---- containing ---- sheets\\nsheets ---- crumpled_on ---- bed\\n\\nFrame 000089:\\n\\nyoung_man ---- lying_on ---- bed\\nbed ---- against ---- wall\\nbed ---- covered_with ---- bedspread\\nbedspread ---- color ---- white\\nbed ---- beside ---- bedside_table\\nbedside_table ---- holding ---- lamp\\nlamp ---- on_top_of ---- bedside_table\\nwall ---- color ---- white\\nbed ---- beneath ---- rug\\nrug ---- color ---- white\\nbed ---- beside ---- curtains\\ncurtains ---- hanging_on ---- wall\\nwall ---- color ---- white\\nbed ---- with ---- pillow\\npillow ---- color ---- white\\nbed ---- with ---- wall_art\\nwall_art ---- hanging_on ---- wall\\nwall ---- color ---- white\\n\\nFrame 000127:\\n\\nman ---- sitting_on ---- mattress\\nmattress ---- on ---- bed\\nbed ---- with ---- headboard\\nheadboard ---- behind ---- man\\nblanket ---- covering ---- mattress\\nblanket ---- on ---- mattress\\ndark_clothing ---- draped_over ---- bed\\ndark_clothing ---- covering ---- mattress\\nshoe ---- on ---- mattress\\nshoe ---- near ---- blanket\\nshoe ---- on ---- bed\\nman ---- looking_at ---- shoe\\nbed ---- in ---- room\\nroom ---- with ---- wooden_floor\\n\\nFrame 000159:\\n\\nman ---- sitting_on ---- bed\\nbed ---- against ---- wall\\nbed ---- supporting ---- bedding\\nbedding ---- consisting_of ---- duvet\\nbedding ---- consisting_of ---- sheet\\nduvet ---- on_top_of ---- bedding\\nsheet ---- on_top_of ---- bedding\\nbed ---- next_to ---- bedside_table\\nbedside_table ---- supporting ---- lamp\\nlamp ---- on_top_of ---- bedside_table\\nlamp ---- emitting_light_onto ---- bedding\\nlamp ---- supporting ---- lampshade\\nlampshade ---- on_top_of ---- lamp\\nlamp ---- supporting ---- lamp_base\\nlamp_base ---- on_top_of ---- lamp\\nbed ---- next_to ---- books\\nbooks ---- on_top_of ---- bedside_table\\nbed ---- next_to ---- man\\nman ---- looking_at ---- lamp\\nbed ---- supporting ---- man\\n\\nFrame 000235:\\n\\nyoung_man ---- sitting_on ---- bed\\nbed ---- against ---- wall\\nbed ---- containing ---- pillow\\npillow ---- positioned_near ---- young_man\\nbedside_table ---- located_to ---- right_of ---- bed\\nlamp ---- sitting_on ---- bedside_table\\nlampshade ---- attached_to ---- lamp_base\\nbooks ---- stacked_on ---- bedside_table\\nbook_stack ---- on_top_of ---- books\\nbed ---- containing ---- bed_sheets\\nbed_sheets ---- covering ---- mattress\\nblanket ---- draped_over ---- right_side_of ---- bed\\nbed ---- situated_on ---- floor\\nbed ---- containing ---- bed_frame\\n\\n</STSG>\\n\\nGiven the following question:\\n<Q>\\nWhat did the person do with the bed?\\n<Q>\\n\\nAnd the following alternatives:\\n<Alternatives>\\nA. Lied on.\\nB. Ate.\\nC. Sat on.\\nD. Put down.\\n</Alternatives>\\n\\nProvide an answer to the above question reasoning step by step on the Spatio-Temporal Scene-Graph (STSG) and choosing one of the alternatives.'},\n",
       "   {'content': 'Okay, let\\'s analyze the Spatio-Temporal Scene Graph to answer the question: \"What did the person do with the bed?\"\\n\\n1. **Identify Relevant Frames:** We need to find frames where people are interacting with the bed. Let\\'s look for verbs like \"lying_on\", \"sitting_on\", \"supporting\", \"containing\", etc.\\n\\n2. **Analyze Frames for Actions:**\\n   * **Frame 000019:** “woman ---- lying_on ---- bed” – The woman is lying on the bed.\\n   * **Frame 000054:** “young_man ---- lying_on ---- bed” – The young man is lying on the bed.\\n   * **Frame 000089:** “young_man ---- lying_on ---- bed” – The young man is lying on the bed.\\n   * **Frame 000127:** “man ---- sitting_on ---- mattress” – The man is sitting on the mattress (which is on the bed).\\n   * **Frame 000159:** “man ---- sitting_on ---- bed” – The man is sitting on the bed.\\n   * **Frame 000235:** “young_man ---- sitting_on ---- bed” – The young man is sitting on the bed.\\n\\n3. **Determine the Most Common Action:**  Multiple frames show people lying on or sitting on the bed.\\n\\n4. **Select the Best Alternative:** Based on the analysis, the most accurate alternative is **A. Lied on.** because it encompasses the most frequent actions described in the graph.\\n\\n**Final Answer: A**\\n',\n",
       "    'role': 'assistant'},\n",
       "   {'role': 'user',\n",
       "    'content': '        Therefore the final answer is?\\n        \\n        Your response must be provided in valid JSON format as follows:\\n        {\"answer\": \"your complete answer here\"}\\n        \\n        IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\\n        Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \\n        should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.        '},\n",
       "   {'role': 'assistant',\n",
       "    'content': '```json\\n{\"answer\": \"A. Lied on.\"}\\n```'}]},\n",
       " {'qid': 'Sequence_T1_5784',\n",
       "  'chat_history': [{'role': 'user',\n",
       "    'content': 'Please carefully read the following Spatio-Temporal Scene Graph delimited by the <STSG> tags and provide an answer to the question below:\\n\\n<STSG>\\n\\nFrame 000223:\\n\\nwoman ---- sitting_on ---- sofa\\nsofa ---- positioned_infront_of ---- coffee_table\\ncoffee_table ---- positioned_infront_of ---- lamp\\nlamp ---- emitting_light_on ---- coffee_table\\nartwork ---- hanging_on ---- wall\\nwall ---- positioned_behind ---- sofa\\nlamp ---- casting_shadow_on ---- coffee_table\\nwoman ---- looking_at ---- artwork\\nsofa ---- positioned_on ---- floor\\nartwork ---- part_of ---- wall\\nfloor ---- supporting ---- sofa\\nwoman ---- occupying ---- space\\n\\nFrame 000247:\\n\\nwoman ---- sitting_on ---- sofa\\nsofa ---- part_of ---- room\\nwoman ---- looking_at ---- artwork\\nartwork ---- hanging_on ---- wall\\nwall ---- behind ---- sofa\\ncoffee_table ---- in_front_of ---- sofa\\nlamp ---- on_top_of ---- coffee_table\\nlamp ---- casting_shadow_on ---- rug\\nrug ---- covering ---- floor\\nsofa ---- supporting ---- woman\\nartwork ---- framed_on ---- wall\\nrug ---- under ---- sofa\\nwoman ---- wearing ---- shirt\\nshirt ---- on ---- woman\\nsofa ---- large ---- room\\nroom ---- containing ---- woman\\n\\nFrame 000278:\\n\\nwoman ---- sitting_on ---- sofa\\nsofa ---- located_on ---- floor\\nwoman ---- looking_at ---- lamp\\nlamp ---- on ---- table\\ntable ---- located_on ---- floor\\nlamp ---- emitting_light ---- room\\nroom ---- illuminated_by ---- lamp\\ntable ---- supporting ---- lamp\\nlamp ---- positioned_on ---- table\\nroom ---- containing ---- sofa\\nroom ---- containing ---- lamp\\nroom ---- containing ---- table\\nroom ---- containing ---- woman\\nsofa ---- located_behind ---- woman\\nroom ---- containing ---- curtains\\nroom ---- containing ---- wall\\n\\nFrame 000286:\\n\\nwoman ---- sitting_on ---- sofa\\nsofa ---- in_front_of ---- coffee_table\\ncoffee_table ---- in_front_of ---- wall\\nwall ---- has_artwork ---- painting\\npainting ---- hanging_on ---- wall\\nlamp ---- standing_behind ---- sofa\\nsofa ---- in_front_of ---- painting\\npainting ---- above ---- coffee_table\\nlamp ---- casting_light_on ---- sofa\\nwoman ---- looking_at ---- painting\\nsofa ---- on ---- rug\\npainting ---- above ---- sofa\\nrug ---- under ---- sofa\\nlamp ---- on ---- floor\\npainting ---- adjacent_to ---- sofa\\n\\nFrame 000317:\\n\\nwoman ---- sitting_on ---- sofa\\nsofa ---- positioned_in_front_of ---- coffee_table\\ncoffee_table ---- positioned_in_front_of ---- artwork\\nartwork ---- hanging_on ---- wall\\nlamp ---- on_top_of ---- coffee_table\\nlamp ---- illuminating ---- sofa\\nwoman ---- looking_at ---- artwork\\nrug ---- partially_covering ---- floor\\nsofa ---- surrounded_by ---- rug\\nwall ---- supporting ---- artwork\\nfloor ---- beneath ---- rug\\nsofa ---- adjacent_to ---- wall\\n\\nFrame 000345:\\n\\nwoman ---- sitting_on ---- sofa\\nwoman ---- next_to ---- child\\nchild ---- sitting_on ---- sofa\\nsofa ---- on ---- floor\\nsofa ---- in_front_of ---- table\\ntable ---- on ---- floor\\nlamp ---- on_top_of ---- table\\nlampshade ---- attached_to ---- lamp\\nrug ---- on ---- floor\\nartwork ---- hanging_on ---- wall\\nwall ---- behind ---- sofa\\nlamp ---- emitting_light_onto ---- sofa\\nchild ---- looking_at ---- lamp\\nwoman ---- holding ---- small_object\\nsmall_object ---- on ---- rug\\n\\nFrame 000421:\\n\\nwoman ---- sitting_on ---- sofa\\nwoman ---- holding ---- white_cushion\\nwhite_cushion ---- on ---- sofa\\nsofa ---- adjacent_to ---- wooden_chair\\nwooden_chair ---- adjacent_to ---- lamp\\nlamp ---- on ---- small_table\\nsmall_table ---- adjacent_to ---- wooden_chair\\nrug ---- covering ---- floor\\nwall ---- containing ---- artwork\\nartwork ---- hanging_on ---- wall\\nwoman ---- looking_at ---- lamp\\nwhite_cushion ---- part_of ---- sofa\\nsmall_table ---- supporting ---- lamp\\nfloor ---- beneath ---- rug\\n\\nFrame 000490:\\n\\nsofa ---- positioned_infront_of ---- coffee_table\\ncoffee_table ---- positioned_infront_of ---- sofa\\nsofa ---- has_on_top ---- throw_pillow\\nsofa ---- has_on_top ---- remote_control\\nsofa ---- has_on_top ---- magazine\\nsofa ---- has_on_top ---- small_object\\nlamp ---- positioned_on_top_of ---- coffee_table\\nsofa ---- positioned_infront_of ---- lamp\\nrug ---- covers ---- floor\\nsofa ---- positioned_infront_of ---- rug\\nwall ---- has_on_it ---- picture_frame\\nsofa ---- positioned_infront_of ---- wall\\nfloor ---- covered_by ---- rug\\nlamp ---- emits_light_on ---- sofa\\nwall ---- has_on_it ---- lamp\\npicture_frame ---- hangs_on ---- wall\\nsofa ---- positioned_infront_of ---- picture_frame\\n\\nFrame 000540:\\n\\nwoman ---- sitting_on ---- sofa_left\\nwoman ---- looking_at ---- coffee_table\\nsofa_left ---- adjacent_to ---- sofa_right\\ncoffee_table ---- on_top_of ---- sofa_right\\nlamp ---- on_top_of ---- coffee_table\\nlamp ---- illuminating ---- coffee_table\\nrug ---- covering ---- floor\\nrug ---- surrounding ---- sofa_left\\nrug ---- surrounding ---- sofa_right\\nartwork ---- hanging_on ---- wall\\nwall ---- behind ---- sofa_left\\nwall ---- behind ---- sofa_right\\nwindow ---- behind ---- curtain\\ncurtain ---- covering ---- window\\nrug ---- adjacent_to ---- wall\\nartwork ---- adjacent_to ---- wall\\n\\nFrame 000586:\\n\\nwoman ---- sitting_on ---- sofa\\nsofa ---- adjacent_to ---- coffee_table\\ncoffee_table ---- supporting ---- lamp\\nlamp ---- on_top_of ---- coffee_table\\nartwork ---- hanging_on ---- wall\\nwall ---- background_to ---- sofa\\nrug ---- covering ---- floor\\nsofa ---- adjacent_to ---- artwork\\nwoman ---- looking_at ---- artwork\\nman ---- sitting_on ---- sofa\\nrug ---- adjacent_to ---- wall\\nman ---- adjacent_to ---- woman\\nwindow ---- visible_through ---- wall\\ncurtains ---- hanging_in ---- window\\nrug ---- adjacent_to ---- curtains\\n\\n</STSG>\\n\\nGiven the following question:\\n<Q>\\nWhich object did the person lie on after they held the pillow?\\n<Q>\\n\\nAnd the following alternatives:\\n<Alternatives>\\nA. The bed.\\nB. The sofa/couch.\\nC. The floor.\\nD. The dish.\\n</Alternatives>\\n\\nProvide an answer to the above question reasoning step by step on the Spatio-Temporal Scene-Graph (STSG) and choosing one of the alternatives.'},\n",
       "   {'content': 'Okay, let\\'s analyze the Spatio-Temporal Scene Graph to answer the question: \"Which object did the person lie on after they held the pillow?\"\\n\\n1. **Identify Relevant Frames:** We need to find frames where the person (woman) is holding a pillow and then lying down.\\n\\n2. **Frame 000345:** This frame shows \"woman ---- holding ---- small_object\" and \"small_object ---- on ---- rug\". This indicates the woman is holding something (likely a pillow) on the rug.\\n\\n3. **Frame 000345:** This frame also shows \"woman ---- sitting_on ---- sofa\". This confirms the woman is sitting on the sofa.\\n\\n4. **Frame 000540:** This frame shows \"woman ---- sitting_on ---- sofa_left\" and \"sofa_left ---- adjacent_to ---- sofa_right\". This confirms the woman is sitting on the sofa.\\n\\n5. **Synthesize the Information:** The woman is holding a small object (likely a pillow) on the rug and then is sitting on the sofa.\\n\\n6. **Choose the Best Alternative:** Based on this analysis, the correct answer is B. The sofa/couch.\\n\\n**Final Answer: B**\\n',\n",
       "    'role': 'assistant'},\n",
       "   {'role': 'user',\n",
       "    'content': '        Therefore the final answer is?\\n        \\n        Your response must be provided in valid JSON format as follows:\\n        {\"answer\": \"your complete answer here\"}\\n        \\n        IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\\n        Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \\n        should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.        '},\n",
       "   {'role': 'assistant',\n",
       "    'content': '```json\\n{\"answer\": \"B. The sofa/couch.\"}\\n```'}]},\n",
       " {'qid': 'Interaction_T2_3935',\n",
       "  'chat_history': [{'role': 'user',\n",
       "    'content': 'Please carefully read the following Spatio-Temporal Scene Graph delimited by the <STSG> tags and provide an answer to the question below:\\n\\n<STSG>\\n\\nFrame 000012:\\n\\nwoman ---- holding ---- cardboard_box\\ncardboard_box ---- on ---- floor\\nwoman ---- looking_at ---- cardboard_box\\ncardboard_box ---- containing ---- white_paper\\nwhite_paper ---- inside ---- cardboard_box\\nwoman ---- wearing ---- striped_shirt\\nstriped_shirt ---- on ---- woman\\nwoman ---- sitting_near ---- wooden_chair\\nwooden_chair ---- behind ---- woman\\nwooden_chair ---- in_front_of ---- floor\\ncardboard_box ---- adjacent_to ---- wooden_chair\\nwoman ---- positioned_in_front_of ---- wooden_chair\\nfloor ---- supporting ---- cardboard_box\\n \\nFrame 000033:\\n\\nwoman ---- sitting_on ---- chair\\nwoman ---- holding ---- backpack\\nbackpack ---- in_front_of ---- woman\\nbackpack ---- supporting ---- straps\\nstraps ---- extending_to ---- woman\\nbackpack ---- positioned_on ---- floor\\nchair ---- located_behind ---- woman\\nchair ---- positioned_on ---- floor\\nbackpack ---- in_front_of ---- chair\\nwoman ---- looking_at ---- backpack\\nbackpack ---- on_top_of ---- floor\\nwoman ---- wearing ---- shirt\\nshirt ---- part_of ---- woman\\nwoman ---- wearing ---- pants\\npants ---- part_of ---- woman\\n\\nFrame 000050:\\n\\nwoman ---- sitting_on ---- chair\\nchair ---- supporting ---- woman\\nchair ---- positioned_behind ---- woman\\nchair ---- holding ---- box\\nbox ---- containing ---- object\\nbox ---- on_top_of ---- chair\\nobject ---- inside ---- box\\nwoman ---- looking_at ---- box\\nwoman ---- positioned_in_front_of ---- chair\\nbox ---- on_floor ---- ground\\nwoman ---- wearing ---- shirt\\nshirt ---- color ---- green_and_white\\nchair ---- made_of ---- wood\\nbox ---- made_of ---- cardboard\\nwoman ---- positioned_on ---- ground\\n\\nFrame 000057:\\n\\nwoman ---- holding ---- brown_box\\nbrown_box ---- in_front_of ---- woman\\nbrown_box ---- on ---- floor\\nwoman ---- looking_at ---- brown_box\\nwoman ---- standing_in_front_of ---- chair\\nchair ---- in_background ---- scene\\nwall ---- behind ---- woman\\nwall ---- supporting ---- scene\\nbrown_box ---- on_top_of ---- floor\\nwoman ---- adjacent_to ---- chair\\nwall ---- supporting ---- chair\\nwoman ---- adjacent_to ---- wall\\n\\nFrame 000063:\\n\\nwoman ---- looking_at ---- cardboard_box\\ncardboard_box ---- contains ---- white_shirt\\ncardboard_box ---- contains ---- dark_sweater\\ncardboard_box ---- contains ---- dark_pants\\nwoman ---- holding ---- cardboard_box\\ncardboard_box ---- sitting_on ---- floor\\nwoman ---- standing_in_front_of ---- cardboard_box\\nwooden_chair ---- located_behind ---- woman\\nwoman ---- positioned_in_front_of ---- wooden_chair\\ncardboard_box ---- adjacent_to ---- floor\\nwoman ---- wearing ---- striped_shirt\\nwoman ---- wearing ---- dark_jeans\\nwoman ---- wearing ---- glasses\\ncardboard_box ---- open_with ---- woman\\n \\nFrame 000079:\\n\\nwoman ---- standing_in_front_of ---- cardboard_box\\ncardboard_box ---- on ---- floor\\nwoman ---- holding ---- folded_jacket\\nfolded_jacket ---- on_top_of ---- cardboard_box\\nwoman ---- looking_at ---- folded_jacket\\nfolded_jacket ---- draped_over ---- cardboard_box\\ncardboard_box ---- adjacent_to ---- wooden_chair\\nwooden_chair ---- in_background ---- image\\nwoman ---- adjacent_to ---- wooden_chair\\nfloor ---- supporting ---- cardboard_box\\nwall ---- background_to ---- image\\nwoman ---- wearing ---- striped_shirt\\nstriped_shirt ---- part_of ---- woman\\nwoman ---- holding ---- glasses\\nglasses ---- on_face ---- woman\\n\\nFrame 000093:\\n\\nwoman ---- standing_in_front_of ---- cardboard_box\\ncardboard_box ---- positioned_in_foreground ---- woman\\nwoman ---- reaching_for ---- cardboard_box\\ncardboard_box ---- containing ---- unknown_objects\\nwoman ---- wearing ---- striped_shirt\\nstriped_shirt ---- belonging_to ---- woman\\nwoman ---- looking_at ---- cardboard_box\\ncardboard_box ---- adjacent_to ---- wooden_chair\\nwooden_chair ---- positioned_behind ---- woman\\nwooden_chair ---- located_in_background ---- woman\\nwall ---- supporting ---- wooden_chair\\nwall ---- forming_backdrop_for ---- scene\\nfloor ---- beneath ---- all_objects\\nfloor ---- supporting ---- wall\\ncardboard_box ---- partially_obscuring ---- wooden_chair\\nwoman ---- adjacent_to ---- wall\\n\\nFrame 000102:\\n\\nwoman ---- sitting_on ---- chair\\nwoman ---- holding ---- glasses\\nwoman ---- looking_at ---- box\\nbox ---- on_top_of ---- chair\\nbox ---- containing ---- nothing\\nchair ---- supporting ---- box\\nbox ---- positioned_above ---- floor\\nwoman ---- wearing ---- shirt\\nshirt ---- on ---- woman\\nglasses ---- on_face ---- woman\\nbox ---- adjacent_to ---- chair\\nwoman ---- adjacent_to ---- box\\nshirt ---- part_of ---- woman\\nbox ---- rectangular_shape\\nwoman ---- human\\nchair ---- wooden\\nbox ---- cardboard\\nglasses ---- eyewear\\nshirt ---- textile\\n\\n</STSG>\\n\\nGiven the following question:\\n<Q>\\nWhat did the person do with the box?\\n<Q>\\n\\nAnd the following alternatives:\\n<Alternatives>\\nA. Closed.\\nB. Put down.\\nC. Threw.\\nD. Opened.\\n</Alternatives>\\n\\nProvide an answer to the above question reasoning step by step on the Spatio-Temporal Scene-Graph (STSG) and choosing one of the alternatives.'},\n",
       "   {'content': 'Okay, let\\'s analyze the Spatio-Temporal Scene Graph to answer the question: \"What did the person do with the box?\"\\n\\n**Step 1: Identify Relevant Frames**\\n\\nThe question refers to \"the box.\" We need to examine frames where the box is a central element and actions related to it are described.  Frames 000012, 000033, 000050, 000057, 000063, 000079, and 000102 are all relevant.\\n\\n**Step 2: Extract Actions Related to the Box**\\n\\nLet\\'s look for verbs associated with the box in these frames:\\n\\n*   **Frame 000012:** “woman ---- holding ---- cardboard_box” – The woman is *holding* the box.\\n*   **Frame 000033:** “woman ---- holding ---- backpack” – The woman is holding a backpack. (This frame is less relevant to the box directly)\\n*   **Frame 000050:** “woman ---- looking_at ---- box” – The woman is looking at the box.\\n*   **Frame 000057:** “woman ---- holding ---- brown_box” – The woman is holding a brown box.\\n*   **Frame 000063:** “woman ---- holding ---- cardboard_box” – The woman is holding a cardboard box.\\n*   **Frame 000079:** “woman ---- standing_in_front_of ---- cardboard_box” – The woman is standing in front of the box.\\n*   **Frame 000102:** “woman ---- holding ---- glasses” – The woman is holding glasses. (This frame is less relevant to the box directly)\\n\\n**Step 3: Determine the Most Accurate Alternative**\\n\\nBased on the extracted actions, the most accurate alternative is **B. Put down.**\\n\\nWhile the woman is *holding* the box in several frames, the question asks what she *did* with it. The context suggests she was actively manipulating it. However, the scene graph doesn\\'t explicitly state she put it down.  The other options are not supported by the scene graph.\\n\\n*   **A. Closed:** The scene graph doesn\\'t indicate the box was closed.\\n*   **C. Threw:** The scene graph doesn\\'t indicate the box was thrown.\\n*   **D. Opened:** The scene graph indicates the box contains items, but doesn\\'t state it was opened.\\n\\n**Final Answer:**\\n\\nB. Put down.',\n",
       "    'role': 'assistant'},\n",
       "   {'role': 'user',\n",
       "    'content': '        Therefore the final answer is?\\n        \\n        Your response must be provided in valid JSON format as follows:\\n        {\"answer\": \"your complete answer here\"}\\n        \\n        IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\\n        Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \\n        should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.        '},\n",
       "   {'role': 'assistant',\n",
       "    'content': '```json\\n{\"answer\": \"B. Put down.\"}\\n```'}]},\n",
       " {'qid': 'Sequence_T1_5311',\n",
       "  'chat_history': [{'role': 'user',\n",
       "    'content': 'Please carefully read the following Spatio-Temporal Scene Graph delimited by the <STSG> tags and provide an answer to the question below:\\n\\n<STSG>\\n\\nFrame 000099:\\n\\nman ---- standing_in_front_of ---- piano\\npiano ---- against ---- wall\\npiano ---- on ---- piano_bench\\npiano_bench ---- in_front_of ---- piano\\nman ---- looking_at ---- piano\\nman ---- standing_near ---- door\\ndoor ---- with ---- curtains\\npiano ---- on_top_of ---- piano_bench\\nlamp ---- on ---- piano_bench\\nlamp ---- next_to ---- flowers\\nflowers ---- in ---- vase\\nvase ---- on ---- piano_bench\\ntable ---- behind ---- piano\\ntable ---- holding ---- books\\nbooks ---- on_top_of ---- table\\nwall ---- supporting ---- door\\ndoor ---- with ---- curtains\\n\\nFrame 000134:\\n\\nyoung_man ---- sitting_on ---- wooden_chair\\nwooden_chair ---- in_front_of ---- piano\\npiano ---- against ---- wall\\npiano ---- with ---- piano_bench\\npiano_bench ---- in_front_of ---- piano\\npiano ---- adjacent_to ---- door\\npiano ---- with ---- window\\nwindow ---- with ---- curtains\\ncurtains ---- hanging_on ---- window\\nyoung_man ---- looking_at ---- piano\\npiano ---- with ---- wall\\nwall ---- enclosing ---- room\\nroom ---- containing ---- young_man\\n\\nFrame 000166:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- adjacent_to ---- coffee_table\\ncoffee_table ---- supporting ---- books\\nbooks ---- stacked_on ---- coffee_table\\nman ---- looking_at ---- coffee_table\\nlamp ---- behind ---- sofa\\nsofa ---- adjacent_to ---- lamp\\nrug ---- covering ---- floor\\nman ---- standing_on ---- rug\\nwindow ---- behind ---- door\\ndoor ---- adjacent_to ---- window\\nbooks ---- on_top_of ---- coffee_table\\nman ---- holding ---- books\\n\\nFrame 000188:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- positioned_to_left_of ---- man\\nman ---- facing ---- coffee_table\\ncoffee_table ---- positioned_in_front_of ---- sofa\\ncoffee_table ---- supporting ---- lamp\\nlamp ---- sitting_on ---- coffee_table\\ncoffee_table ---- holding ---- books\\nbooks ---- stacked_on ---- coffee_table\\nrug ---- covering ---- floor\\nman ---- standing_on ---- rug\\nsofa ---- positioned_against ---- wall\\nwall ---- enclosing ---- room\\nman ---- facing ---- window\\nwindow ---- containing ---- curtains\\ncurtains ---- hanging_in ---- window\\nman ---- standing_in_front_of ---- coffee_table\\n\\nFrame 000203:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- positioned_to_the_left_of ---- man\\ncoffee_table ---- in_front_of ---- sofa\\nlamp ---- on_top_of ---- coffee_table\\nbooks ---- on ---- coffee_table\\ntoy_bicycle ---- leaning_against ---- wall\\nwall ---- behind ---- sofa\\nman ---- looking_at ---- toy_bicycle\\nfloor ---- supporting ---- all_objects\\nwall ---- enclosing ---- room\\nman ---- occupying ---- space\\n\\nFrame 000219:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- adjacent_to ---- wheelchair\\nwheelchair ---- positioned_near ---- man\\nman ---- looking_at ---- wheelchair\\nman ---- facing ---- sofa\\nsofa ---- in_front_of ---- bookshelf\\nbookshelf ---- containing ---- books\\nbooks ---- stacked_on ---- bookshelf\\nman ---- adjacent_to ---- coffee_table\\ncoffee_table ---- in_front_of ---- sofa\\nwall ---- supporting ---- all_objects\\ndoor ---- in_background_of ---- scene\\nlight_fixture ---- above ---- scene\\n\\nFrame 000238:\\n\\nyoung_man ---- standing_in_front_of ---- gray_sofa\\ngray_sofa ---- has_on ---- throw_pillow\\nthrow_pillow ---- resting_on ---- gray_sofa\\nyoung_man ---- holding ---- throw_pillow\\ngray_sofa ---- adjacent_to ---- wooden_table\\nwooden_table ---- has_on ---- wooden_box\\nwooden_box ---- on_top_of ---- wooden_table\\nwooden_table ---- adjacent_to ---- bicycle\\nbicycle ---- behind ---- wooden_table\\nbicycle ---- has_on ---- wheels_of_bicycle\\nwheels_of_bicycle ---- part_of ---- bicycle\\nbicycle ---- has_on ---- handlebars_of_bicycle\\nhandlebars_of_bicycle ---- part_of ---- bicycle\\nbicycle ---- adjacent_to ---- white_door\\nwhite_door ---- in_background ---- scene\\nyoung_man ---- looking_at ---- throw_pillow\\n\\nFrame 000251:\\n\\nwoman ---- standing_in_front_of ---- sofa\\nsofa ---- positioned_in_front_of ---- coffee_table\\ncoffee_table ---- holding ---- lamp\\nlamp ---- on_top_of ---- coffee_table\\nbooks ---- stacked_on ---- coffee_table\\nbicycle_wheel ---- lying_on ---- floor\\nbicycle_frame ---- adjacent_to ---- bicycle_wheel\\nbooks ---- on_top_of ---- coffee_table\\nwoman ---- looking_at ---- bicycle_wheel\\nsofa ---- positioned_in_front_of ---- coffee_table\\nwoman ---- standing_in_front_of ---- sofa\\n\\nFrame 000281:\\n\\nyoung_man ---- standing_in_front_of ---- sofa\\nsofa ---- positioned_behind ---- bike\\nbike ---- located_behind ---- wall\\nwall ---- adjacent_to ---- door\\ndoor ---- located_on ---- wall\\nyoung_man ---- looking_at ---- bike\\nbooks ---- on_top_of ---- coffee_table\\ncoffee_table ---- in_front_of ---- sofa\\nbooks ---- on ---- coffee_table\\nbox ---- located_on ---- floor\\nfloor ---- below ---- sofa\\nfloor ---- below ---- bike\\nyoung_man ---- wearing ---- t_shirt\\nt_shirt ---- part_of ---- young_man\\nyoung_man ---- wearing ---- jeans\\njeans ---- part_of ---- young_man\\n\\nFrame 000312:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- adjacent_to ---- wall\\nsofa ---- supporting ---- coffee_table\\ncoffee_table ---- holding ---- books\\nbooks ---- stacked_on ---- coffee_table\\nman ---- looking_at ---- bike\\nbike ---- behind ---- box\\nbox ---- on_floor ---- room\\nbike ---- behind ---- box\\nbox ---- adjacent_to ---- wall\\nman ---- adjacent_to ---- coffee_table\\nbooks ---- on_top_of ---- coffee_table\\nwall ---- surrounding ---- room\\n\\n</STSG>\\n\\nGiven the following question:\\n<Q>\\nWhich object did the person take after they threw the shoe?\\n<Q>\\n\\nAnd the following alternatives:\\n<Alternatives>\\nA. The phone/camera.\\nB. The box.\\nC. The laptop.\\nD. The towel.\\n</Alternatives>\\n\\nProvide an answer to the above question reasoning step by step on the Spatio-Temporal Scene-Graph (STSG) and choosing one of the alternatives.'},\n",
       "   {'content': 'Okay, let\\'s analyze the Spatio-Temporal Scene Graph to answer the question: \"Which object did the person take after they threw the shoe?\".\\n\\n**Reasoning:**\\n\\n1. **Identify the relevant frames:** We need to find frames where an action involving throwing a shoe occurs. The STSG doesn\\'t explicitly state a shoe was thrown. However, we can infer an action related to a bicycle.\\n\\n2. **Look for actions related to the bicycle:** The STSG contains several frames where a \"bike\" or \"bicycle\" is present.  Frames 000281 and 000312 mention a \"bike\" or \"bicycle\".\\n\\n3. **Analyze the actions around the bicycle:** In Frame 000281, the young man is \"wearing\" a t-shirt and jeans, and is \"looking at\" the bike. In Frame 000312, the young man is \"looking at\" the bike and the bike is \"behind\" a box.\\n\\n4. **Consider the alternatives:**\\n   * A. The phone/camera: No mention of these objects in the STSG.\\n   * B. The box: The young man is looking at the bike *behind* the box.\\n   * C. The laptop: No mention of a laptop.\\n   * D. The towel: No mention of a towel.\\n\\n**Conclusion:**\\n\\nBased on the STSG, the young man is looking at the bike behind the box. Therefore, the most logical answer is **B. The box.**\\n\\n**Final Answer: B**\\n',\n",
       "    'role': 'assistant'},\n",
       "   {'role': 'user',\n",
       "    'content': '        Therefore the final answer is?\\n        \\n        Your response must be provided in valid JSON format as follows:\\n        {\"answer\": \"your complete answer here\"}\\n        \\n        IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\\n        Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \\n        should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.        '},\n",
       "   {'role': 'assistant',\n",
       "    'content': '```json\\n{\"answer\": \"B. The box.\"}\\n```'}]},\n",
       " {'qid': 'Sequence_T1_2219',\n",
       "  'chat_history': [{'role': 'user',\n",
       "    'content': 'Please carefully read the following Spatio-Temporal Scene Graph delimited by the <STSG> tags and provide an answer to the question below:\\n\\n<STSG>\\n\\nFrame 000011:\\n\\nwoman ---- sitting_on ---- chair\\nchair ---- supporting ---- woman\\nwoman ---- wearing ---- pants\\npants ---- covering ---- legs\\npants ---- touching ---- floor\\nwoman ---- wearing ---- shoes\\nshoes ---- in_front_of ---- chair\\nchair ---- has_legs ---- chair_legs\\nchair_legs ---- touching ---- floor\\nwoman ---- looking_at ---- chair\\nchair ---- has_back ---- chair_back\\nchair_back ---- behind ---- woman\\nfloor ---- supporting ---- chair\\nfloor ---- supporting ---- pants\\nfloor ---- supporting ---- shoes\\npants ---- touching ---- floor\\nshoes ---- touching ---- floor\\nwoman ---- in_front_of ---- chair_back\\n\\nFrame 000049:\\n\\nwoman ---- standing_in_front_of ---- sofa\\nsofa ---- positioned_behind ---- chair\\nchair ---- located_on ---- floor\\nwoman ---- wearing ---- sweater\\nsweater ---- color_of ---- green\\nwoman ---- wearing ---- leggings\\nleggings ---- color_of ---- black\\nwoman ---- looking_at ---- lamp\\nlamp ---- located_on ---- wall\\nwall ---- behind ---- sofa\\nfloor ---- supporting ---- chair\\nfloor ---- supporting ---- sofa\\nwall ---- supporting ---- lamp\\nwoman ---- adjacent_to ---- sofa\\n\\nFrame 000076:\\n\\nwoman ---- standing_in_front_of ---- chair\\nchair ---- positioned_on ---- floor\\nchair ---- adjacent_to ---- door\\ndoor ---- located_behind ---- chair\\ndoor ---- against ---- wall\\nwall ---- supporting ---- door\\nwall ---- supporting ---- chair\\nlight_source ---- positioned_above ---- chair\\nlight_source ---- illuminating ---- woman\\nwoman ---- facing ---- door\\nwoman ---- standing_on ---- floor\\nlight_source ---- casting_shadow_on ---- woman\\n\\nFrame 000096:\\n\\nwoman ---- sitting_on ---- chair\\nchair ---- located_on ---- floor\\nlamp ---- located_behind ---- woman\\nlamp ---- located_above ---- lamp_base\\nlamp_base ---- supporting ---- lamp\\nlamp_shade ---- above ---- lamp_base\\nlamp ---- illuminating ---- woman\\nwoman ---- facing ---- lamp\\nchair ---- located_on ---- floor\\nfloor ---- supporting ---- chair\\nwall ---- behind ---- chair\\ndoor ---- visible_in_background ---- chair\\nfloor ---- supporting ---- lamp_base\\n\\nFrame 000120:\\n\\narmchair ---- positioned_in_front_of ---- door\\narmchair ---- illuminated_by ---- floor_lamp\\nfloor_lamp ---- positioned_behind ---- armchair\\nfloor_lamp ---- has_light_bulbs ---- light_bulb\\nlight_bulb ---- located_above ---- armchair\\narmchair ---- on ---- floor\\nfloor_lamp ---- connected_to ---- electrical_cord\\nelectrical_cord ---- runs_along ---- floor\\nfloor ---- supports ---- armchair\\nfloor_lamp ---- has_light ---- light_bulb\\narmchair ---- has_leather_upholstery ---- armchair\\ndoor ---- is_closed ---- door\\narmchair ---- is_brown ---- armchair\\nlight_bulb ---- emits_light ---- light_bulb\\n\\nFrame 000173:\\n\\narmchair ---- positioned_in_front_of ---- floor lamp\\nfloor lamp ---- positioned_on ---- floor\\narmchair ---- positioned_in_front_of ---- floor lamp\\nlampshade ---- attached_to ---- floor lamp\\nlampshade ---- emitting_light ---- armchair\\nlampshade ---- emitting_light ---- armchair\\nfloor lamp ---- emitting_light ---- armchair\\narmchair ---- positioned_in_front_of ---- wall\\nwall ---- serving_as_backdrop_for ---- floor lamp\\nfloor ---- supporting ---- armchair\\nfloor lamp ---- supporting ---- armchair\\nwall ---- supporting ---- floor lamp\\narmchair ---- supporting ---- wall\\n\\nFrame 000209:\\n\\nwoman ---- standing_in_front_of ---- floor_lamp\\nfloor_lamp ---- positioned_in_front_of ---- woman\\nwoman ---- looking_at ---- floor_lamp\\nfloor_lamp ---- standing_on ---- floor\\nwoman ---- wearing ---- green_shirt\\nwoman ---- wearing ---- white_pants\\nfloor_lamp ---- having ---- lamp_shade\\nlamp_shade ---- being_white ---- color\\nwoman ---- sitting_near ---- chair\\nchair ---- positioned_behind ---- woman\\nchair ---- on ---- floor\\nchair ---- having ---- table\\ntable ---- positioned_next_to ---- chair\\ntable ---- having ---- book\\nbook ---- on_top_of ---- table\\nbook ---- having ---- book_cover\\nbook_cover ---- being_dark ---- color\\nwoman ---- near ---- chair\\n\\nFrame 000250:\\n\\nwoman ---- sitting_on ---- chair\\nchair ---- positioned_behind ---- wall\\nwoman ---- wearing ---- shirt\\nshirt ---- is_white ---- shirt\\nwoman ---- wearing ---- sneakers\\nsneakers ---- are_red ---- sneakers\\nchair ---- positioned_behind ---- floor lamp\\nfloor lamp ---- positioned_above ---- chair\\nwall ---- positioned_behind ---- chair\\nfloor lamp ---- positioned_behind ---- wall\\nwoman ---- looking_at ---- floor lamp\\nfloor lamp ---- emitting_light ---- floor lamp\\nwall ---- providing_background ---- scene\\nchair ---- occupying_floor_space ---- floor\\nwoman ---- occupying_chair ---- chair\\n\\n</STSG>\\n\\nGiven the following question:\\n<Q>\\nWhich object did the person sit on after they held the blanket?\\n<Q>\\n\\nAnd the following alternatives:\\n<Alternatives>\\nA. The bed.\\nB. The floor.\\nC. The medicine.\\nD. The sofa/couch.\\n</Alternatives>\\n\\nProvide an answer to the above question reasoning step by step on the Spatio-Temporal Scene-Graph (STSG) and choosing one of the alternatives.'},\n",
       "   {'content': 'Okay, let\\'s analyze the scene graph to answer the question: \"Which object did the person sit on after they held the blanket?\"\\n\\n1. **Understanding the Question:** The question asks about a specific action – sitting on an object *after* holding a blanket.  The \"blanket\" is implied to be a covering or a piece of fabric.\\n\\n2. **Analyzing Relevant Frames:** We need to find frames where the person is sitting on something, and where there\\'s a clear action of holding a covering. Let\\'s look for frames where the woman is sitting.\\n\\n   * **Frame 000011:** The woman is sitting on a chair.\\n   * **Frame 000049:** The woman is sitting on a sofa.\\n   * **Frame 000250:** The woman is sitting on a chair.\\n\\n3. **Identifying the Action:** In Frame 000250, the woman is sitting on a chair. This frame also describes the woman wearing a shirt and sneakers.\\n\\n4. **Evaluating Alternatives:**\\n   * **A. The bed:** There\\'s no mention of a bed in the scene graph.\\n   * **B. The floor:** The woman is sitting *on* a chair, not the floor.\\n   * **C. The medicine:** There\\'s no mention of medicine in the scene graph.\\n   * **D. The sofa/couch:** The woman is sitting on a chair, not a sofa.\\n\\n**Final Answer:**\\n\\nB. The floor. (This is incorrect based on the scene graph. The woman is sitting on a chair.)\\n\\n**Correct Answer:**\\n\\nThe woman is sitting on a chair.\\n',\n",
       "    'role': 'assistant'},\n",
       "   {'role': 'user',\n",
       "    'content': '        Therefore the final answer is?\\n        \\n        Your response must be provided in valid JSON format as follows:\\n        {\"answer\": \"your complete answer here\"}\\n        \\n        IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\\n        Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \\n        should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.        '},\n",
       "   {'role': 'assistant',\n",
       "    'content': '```json\\n{\"answer\": \"B. The floor.\"}\\n```'}]}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "with open(BASE_DIR / 'outputs/responses_to_genframes_gemma3:4b_1604_p1.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "    \n",
    "data[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [o['qid'] for o in data]\n",
    "len(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_DIR / 'src/ids_with_ans.txt', 'w') as f:\n",
    "    for i in ids:\n",
    "        f.write(f\"{i}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a large language model, I don't experience feelings in the same way humans do. However, my systems are functioning optimally, and I'm ready to assist you with your request! 😊 \n",
      "\n",
      "Essentially, I'm doing well and prepared to tackle any reasoning questions you throw my way. \n",
      "\n",
      "Now, let's get to the Spatio-Temporal Scene Graph! Please provide it to me.\n",
      "\n",
      "Response at: 8.0 tk/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I don't experience feelings in the same way humans do. However, my systems are functioning optimally, and I'm ready to assist you with your request! 😊 \\n\\nEssentially, I'm doing well and prepared to tackle any reasoning questions you throw my way. \\n\\nNow, let's get to the Spatio-Temporal Scene Graph! Please provide it to me.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.generate_completion(\"how are you\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_id': 'Interaction_T1_13',\n",
       "  'question': 'Which object was tidied up by the person?',\n",
       "  'choices': {'0': 'The closet/cabinet.',\n",
       "   '1': 'The blanket.',\n",
       "   '2': 'The clothes.',\n",
       "   '3': 'The table.'},\n",
       "  'answer': 2,\n",
       "  'stsg': [['person - on_the_side_of - clothes'],\n",
       "   ['person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - clothes', 'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - on_the_side_of - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - on_the_side_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - beneath - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - on_the_side_of - towel',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - on_the_side_of - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes', 'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - touching - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel', 'person - in_front_of - clothes'],\n",
       "   ['person - holding - blanket', 'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket']]},\n",
       " {'question_id': 'Interaction_T1_14',\n",
       "  'question': 'Which object was tidied up by the person?',\n",
       "  'choices': {'0': 'The blanket.',\n",
       "   '1': 'The table.',\n",
       "   '2': 'The clothes.',\n",
       "   '3': 'The closet/cabinet.'},\n",
       "  'answer': 2,\n",
       "  'stsg': [['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes', 'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - touching - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel', 'person - in_front_of - clothes'],\n",
       "   ['person - holding - blanket', 'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - towel',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - towel',\n",
       "    'person - in_front_of - towel',\n",
       "    'person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes', 'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - towel', 'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - clothes', 'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - in_front_of - towel', 'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - towel', 'person - in_front_of - clothes']]},\n",
       " {'question_id': 'Interaction_T1_31',\n",
       "  'question': 'Which object was thrown by the person?',\n",
       "  'choices': {'0': 'The pillow.',\n",
       "   '1': 'The bag.',\n",
       "   '2': 'The clothes.',\n",
       "   '3': 'The box.'},\n",
       "  'answer': 2,\n",
       "  'stsg': [['person - wearing - clothes', 'person - above - clothes'],\n",
       "   ['person - wearing - clothes', 'person - on_the_side_of - clothes'],\n",
       "   ['person - wearing - clothes', 'person - on_the_side_of - clothes'],\n",
       "   ['person - holding - clothes', 'person - in_front_of - clothes'],\n",
       "   ['person - in_front_of - clothes'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - wearing - shoe',\n",
       "    'person - beneath - shoe'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - on_the_side_of - sofa/couch'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - on_the_side_of - sofa/couch',\n",
       "    'person - on_the_side_of - bed'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - on_the_side_of - sofa/couch',\n",
       "    'person - on_the_side_of - bed'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - on_the_side_of - sofa/couch',\n",
       "    'person - on_the_side_of - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - behind - bed',\n",
       "    'person - beneath - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - behind - bed']]},\n",
       " {'question_id': 'Interaction_T1_32',\n",
       "  'question': 'Which object was put down by the person?',\n",
       "  'choices': {'0': 'The food.',\n",
       "   '1': 'The shoe.',\n",
       "   '2': 'The blanket.',\n",
       "   '3': 'The sandwich.'},\n",
       "  'answer': 1,\n",
       "  'stsg': [['person - on_the_side_of - clothes',\n",
       "    'person - wearing - shoe',\n",
       "    'person - beneath - shoe'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - on_the_side_of - sofa/couch'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - on_the_side_of - sofa/couch',\n",
       "    'person - on_the_side_of - bed'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - on_the_side_of - sofa/couch',\n",
       "    'person - on_the_side_of - bed'],\n",
       "   ['person - on_the_side_of - clothes',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - on_the_side_of - sofa/couch',\n",
       "    'person - on_the_side_of - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - behind - bed',\n",
       "    'person - beneath - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - sitting_on - sofa/couch',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - sitting_on - bed',\n",
       "    'person - beneath - bed',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - sitting_on - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - on_the_side_of - sofa/couch',\n",
       "    'person - sitting_on - bed',\n",
       "    'person - beneath - bed',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - sitting_on - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - sitting_on - bed',\n",
       "    'person - beneath - bed',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - on_the_side_of - clothes',\n",
       "    'person - sitting_on - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - sitting_on - bed',\n",
       "    'person - beneath - bed',\n",
       "    'person - behind - bed'],\n",
       "   ['person - sitting_on - bed',\n",
       "    'person - beneath - bed',\n",
       "    'person - behind - bed'],\n",
       "   ['person - behind - clothes',\n",
       "    'person - sitting_on - sofa/couch',\n",
       "    'person - behind - sofa/couch',\n",
       "    'person - beneath - sofa/couch',\n",
       "    'person - holding - shoe',\n",
       "    'person - wearing - shoe',\n",
       "    'person - in_front_of - shoe',\n",
       "    'person - sitting_on - bed',\n",
       "    'person - beneath - bed',\n",
       "    'person - behind - bed']]},\n",
       " {'question_id': 'Interaction_T1_40',\n",
       "  'question': 'Which object was tidied up by the person?',\n",
       "  'choices': {'0': 'The broom.',\n",
       "   '1': 'The closet/cabinet.',\n",
       "   '2': 'The blanket.',\n",
       "   '3': 'The table.'},\n",
       "  'answer': 1,\n",
       "  'stsg': [['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - touching - shelf',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - shelf',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - holding - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket',\n",
       "    'person - on_the_side_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - phone/camera',\n",
       "    'person - on_the_side_of - phone/camera',\n",
       "    'person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - touching - blanket',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - touching - clothes',\n",
       "    'person - in_front_of - clothes',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - clothes',\n",
       "    'person - in_front_of - closet/cabinet',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - phone/camera',\n",
       "    'person - in_front_of - phone/camera',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - phone/camera', 'person - in_front_of - phone/camera'],\n",
       "   ['person - holding - phone/camera',\n",
       "    'person - in_front_of - phone/camera',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - in_front_of - closet/cabinet', 'person - in_front_of - blanket'],\n",
       "   ['person - holding - phone/camera',\n",
       "    'person - in_front_of - phone/camera',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - phone/camera',\n",
       "    'person - in_front_of - phone/camera',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - book',\n",
       "    'person - in_front_of - book',\n",
       "    'person - holding - phone/camera',\n",
       "    'person - in_front_of - phone/camera',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - phone/camera',\n",
       "    'person - in_front_of - phone/camera',\n",
       "    'person - in_front_of - blanket'],\n",
       "   ['person - holding - phone/camera',\n",
       "    'person - in_front_of - phone/camera',\n",
       "    'person - in_front_of - blanket']]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "with open(BASE_DIR / \"data/datasets/STAR_QA_and_stsg_val.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "\n",
    "data[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7098, 7098)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [d['question_id'] for d in star_data]\n",
    "len(ids), len(set(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interaction_T3_6051'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "half_size = len(ids) // 2\n",
    "random.shuffle(ids)\n",
    "first_half = ids[:half_size]\n",
    "second_half = ids[half_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interaction_T2_3150'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_half[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../src/val1_ids.txt', 'w') as f:\n",
    "    for i in first_half:\n",
    "        f.write(f\"{i}\\n\")\n",
    "        \n",
    "with open('../src/val2_ids.txt', 'w') as f:\n",
    "    for i in second_half:\n",
    "        f.write(f\"{i}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PromptDataset.__init__() missing 1 required positional argument: 'prompt_formatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mPromptDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs/responses_genframes:7b_202504010_22:47:00.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: PromptDataset.__init__() missing 1 required positional argument: 'prompt_formatter'"
     ]
    }
   ],
   "source": [
    "a = PromptDataset(BASE_DIR / 'outputs/responses_genframes:7b_202504010_22:47:00.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_positions = sorted(load_positions.items(), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
