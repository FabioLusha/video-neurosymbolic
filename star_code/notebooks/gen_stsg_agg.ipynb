{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = Path.cwd().parent\n",
    "\n",
    "f_0 = WORK_DIR / \"outputs/responses_genframes:7b_202504010_22:47:00.jsonl\"\n",
    "\n",
    "f_1 = WORK_DIR / \"outputs/genframes_val1.jsonl\"\n",
    "f_2 = WORK_DIR / \"outputs/genframes_val2.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 389, 385, 385, 774)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1 = []\n",
    "with open(f_1) as in_f:\n",
    "    part1 = [json.loads(line) for line in in_f.readlines()]\n",
    "\n",
    "part2 = []\n",
    "with open(f_2) as in_f:\n",
    "    part2 = [json.loads(line) for line in in_f.readlines()]\n",
    "\n",
    "p1_keys = set([d['qid'] for d in part1])\n",
    "p2_keys = set([d['qid'] for d in part2])\n",
    "\n",
    "\n",
    "len(part1), len(p1_keys), len(part2), len(p2_keys), len(p1_keys.union(p2_keys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1bis = WORK_DIR / \"outputs/genframes_val1_part2.jsonl\"\n",
    "f_2bis = WORK_DIR / \"outputs/genframes_val2_part2.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 130, 90, 90, 220)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1bis = []\n",
    "with open(f_1bis) as in_f:\n",
    "    part1bis = [json.loads(line) for line in in_f.readlines()]\n",
    "\n",
    "part2bis = []\n",
    "with open(f_2bis) as in_f:\n",
    "    part2bis = [json.loads(line) for line in in_f.readlines()]\n",
    "\n",
    "p1bis_keys = set([d['qid'] for d in part1bis])\n",
    "p2bis_keys = set([d['qid'] for d in part2bis])\n",
    "\n",
    "\n",
    "len(part1bis), len(p1bis_keys), len(part2bis), len(p2bis_keys), len(p1bis_keys | p2bis_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1bis_keys | p2bis_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = []\n",
    "with open(WORK_DIR / \"data/datasets/STAR_QA_and_stsg_val.json\") as f:\n",
    "    qa_data = json.load(f)\n",
    "    \n",
    "id_to_qadata = {d['question_id']: d for d in qa_data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 'Sequence_T4_281',\n",
       " 'question': 'What happened before the person threw the clothes?',\n",
       " 'choices': {'0': 'Took the box.',\n",
       "  '1': 'Put down the paper/notebook.',\n",
       "  '2': 'Closed the book.',\n",
       "  '3': 'Sat on the sofa/couch.'},\n",
       " 'answer': 3,\n",
       " 'stsg': '\\nFrame 000004:\\n\\nFrame 000011:\\n\\nyoung_man ---- sitting_on ---- chair\\nyoung_man ---- looking_at ---- wall_hanging\\nwall_hanging ---- behind ---- young_man\\nwall_hanging ---- above ---- floor\\nchair ---- below ---- young_man\\nwall ---- behind ---- wall_hanging\\nwall ---- supporting ---- floor\\nlight_fixture ---- above ---- wall_hanging\\nwall ---- supporting ---- floor\\nwall_hanging ---- dominating ---- scene\\nfloor ---- supporting ---- chair\\nwall ---- supporting ---- floor\\n\\nFrame 000023:\\n\\nwoman ---- sitting_on ---- chair\\nwoman ---- looking_at ---- tapestry\\ntapestry ---- hanging_on ---- wall\\nwall ---- made_of ---- wood\\nchair ---- located_near ---- tapestry\\ntapestry ---- positioned_above ---- chair\\nwall ---- surrounding ---- woman\\nwoman ---- in_front_of ---- wall\\ntapestry ---- dominating_scene ---- room\\nwall ---- supporting ---- tapestry\\nwoman ---- in_background ---- room\\ntapestry ---- textured_pattern ---- wall\\nwoman ---- gazing_at ---- tapestry\\nchair ---- adjacent_to ---- tapestry\\nwall ---- holding ---- tapestry\\nwoman ---- in_foreground ---- room\\n\\nFrame 000029:\\n\\nman ---- standing_in_front_of ---- painting\\npainting ---- hanging_on ---- wall\\nwall ---- adjacent_to ---- door\\nman ---- holding_edge_of ---- painting\\npainting ---- above ---- man\\npainting ---- filling_background ---- room\\nman ---- looking_at ---- painting\\nwall ---- supporting ---- painting\\npainting ---- dominating ---- room\\nman ---- on_floor ---- room\\nwall ---- adjacent_to ---- floor\\npainting ---- adjacent_to ---- wall\\nman ---- part_of ---- room\\npainting ---- adjacent_to ---- floor\\n\\nFrame 000033:\\n\\nman ---- standing_in_front_of ---- wall\\nwall ---- hanging_curtain ---- curtain\\ncurtain ---- behind ---- television\\ntelevision ---- mounted_on ---- wall\\nman ---- holding ---- remote_control\\nremote_control ---- on ---- table\\ntable ---- on ---- floor\\nman ---- looking_at ---- television\\nwall ---- adjacent_to ---- floor\\nman ---- adjacent_to ---- wall\\nremote_control ---- on_top_of ---- table\\nfloor ---- supporting ---- table\\nwall ---- adjacent_to ---- television\\n\\nFrame 000037:\\n\\nman ---- standing_in_front_of ---- wall\\nwall ---- supporting ---- curtain\\ncurtain ---- hanging_from ---- wall\\nman ---- looking_at ---- television\\ntelevision ---- mounted_on ---- wall\\nwall ---- supporting ---- rug\\nrug ---- covering ---- floor\\ntable ---- placed_on ---- floor\\nlamp ---- placed_on ---- table\\nlampshade ---- attached_to ---- lamp\\nman ---- standing_behind ---- chair\\nchair ---- positioned_behind ---- man\\ntable ---- supporting ---- lamp\\nlamp ---- supporting ---- lampshade\\nrug ---- surrounding ---- floor\\n\\nFrame 000043:\\n\\nman ---- standing_in_front_of ---- wall\\nwall ---- supporting ---- curtain\\ncurtain ---- hanging_from ---- ceiling\\nceiling ---- above ---- room\\nman ---- looking_at ---- curtain\\ncurtain ---- held_by ---- man\\nwall ---- adjacent_to ---- television\\ntelevision ---- positioned_behind ---- table\\ntable ---- supporting ---- chair\\nchair ---- sitting_on ---- table\\nman ---- adjacent_to ---- television\\nwall ---- adjacent_to ---- television\\nceiling ---- above ---- curtain\\nwall ---- adjacent_to ---- television\\n\\nFrame 000050:\\n\\nyoung_man ---- standing_in_front_of ---- wall\\nyoung_man ---- wearing ---- green_sweatshirt\\nyoung_man ---- wearing ---- black_pants\\nyoung_man ---- holding ---- small_brown_object\\nsmall_brown_object ---- on_top_of ---- wooden_table\\nwooden_table ---- in_front_of ---- young_man\\ngreen_sweatshirt ---- part_of ---- young_man\\nblack_pants ---- part_of ---- young_man\\nwall ---- behind ---- television\\ntelevision ---- behind ---- green_curtain\\ngreen_curtain ---- hanging_on ---- wall\\nwall ---- supporting ---- television\\ntelevision ---- in_front_of ---- green_curtain\\nyoung_man ---- looking_at ---- television\\nwall ---- containing ---- television\\nwooden_table ---- adjacent_to ---- young_man\\nsmall_brown_object ---- on ---- wooden_table\\n'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_content = part1 + part2\n",
    "\n",
    "gen_data = []\n",
    "for e in gen_content:\n",
    "    datum = id_to_qadata[e['qid']]\n",
    "    datum['stsg'] = e['stsg']\n",
    "    gen_data.append(datum)\n",
    "    \n",
    "gen_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WORK_DIR / 'data/datasets/STAR_QA_and_gen_stsg_p2.json', 'w') as o_f:\n",
    "    json.dump(gen_data, o_f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7098"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keys = set(id_to_qadata.keys())\n",
    "len(all_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3549, 3549, 0, 7098, 7098)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ids = list(all_keys)\n",
    "half_size = len(ids) // 2\n",
    "random.shuffle(ids)\n",
    "first_half = set(ids[:half_size])\n",
    "second_half = set(ids[half_size:])\n",
    "\n",
    "len(first_half), len(second_half), len(first_half & second_half), len(first_half | second_half), len(all_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 130, 519, 385, 90, 475, 774, 220, 0, 994)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = p1_keys | p1bis_keys\n",
    "k2 = p2_keys | p2bis_keys\n",
    "\n",
    "len(p1_keys), len(p1bis_keys), len(k1), len(p2_keys), len(p2bis_keys), len(k2), len(p1_keys | p2_keys), len(p1bis_keys | p2bis_keys), len(k1 & k2), len(k1 | k2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6104, 994, 7098, 7098)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(all_keys - k1 - k2)\n",
    "\n",
    "len(ids), len(k1 | k2), len(ids) + len(k1 | k2), len(all_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3052, 3052, 0, 6104, 7098)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "half_size = len(ids) // 2\n",
    "random.shuffle(ids)\n",
    "first_half = set(ids[:half_size])\n",
    "second_half = set(ids[half_size:])\n",
    "\n",
    "len(first_half), len(second_half), len(first_half & second_half), len(first_half | second_half), len(first_half | second_half | k1 | k2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3571, 3527, 0, 7098, 7098)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_half = first_half | k1\n",
    "second_half = second_half | k2\n",
    "\n",
    "len(first_half), len(second_half), len(first_half & second_half), len(first_half | second_half), len(first_half | second_half | k1 | k2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WORK_DIR / 'src/val1_ids.txt', 'w') as f:\n",
    "    for i in first_half:\n",
    "        f.write(f\"{i}\\n\")\n",
    "        \n",
    "with open(WORK_DIR / 'src/val2_ids.txt', 'w') as f:\n",
    "    for i in second_half:\n",
    "        f.write(f\"{i}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((first_half - k1)  & (second_half -k2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WORK_DIR / 'src/rem_val1_ids.txt', 'w') as f:\n",
    "    for i in (first_half - k1):\n",
    "        f.write(f\"{i}\\n\")\n",
    "        \n",
    "with open(WORK_DIR / 'src/rem_val2_ids.txt', 'w') as f:\n",
    "    for i in (second_half - k2):\n",
    "        f.write(f\"{i}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1_new = k1 - p1_keys\n",
    "k2_new = k2 - p2_keys\n",
    "\n",
    "\n",
    "len(all_keys) - len(k1_new) - len(k2_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3030"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k1 - p1_keys - p1bis_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WORK_DIR / 'data/datasets/STAR_QA_and_gen_stsg.json', 'w') as o_f:\n",
    "    json.dump(gen_data, o_f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = []\n",
    "with open(WORK_DIR / 'outputs/responses_genframes_gemma3:4b_1504_22:19.jsonl', 'r') as f:\n",
    "    content = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "len(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 'Interaction_T1_14',\n",
       " 'chat_history': [{'role': 'user',\n",
       "   'content': 'Please carefully read the following Spatio-Temporal Scene Graph delimited by the <STSG> tags and provide an answer to the question below:\\n\\n<STSG>\\n\\nFrame 000286:\\n\\nman ---- holding ---- spray_bottle\\nspray_bottle ---- aimed_at ---- sofa\\nsofa ---- covered_with ---- cushion\\ncushion ---- part_of ---- sofa\\nsofa ---- on ---- floor\\nfloor ---- covered_with ---- tile\\ntile ---- part_of ---- floor\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- on ---- wall\\nwall ---- behind ---- man\\nman ---- wearing ---- t-shirt\\nt-shirt ---- part_of ---- man\\nman ---- wearing ---- shorts\\nshorts ---- part_of ---- man\\nsofa ---- on ---- floor\\nfloor ---- covered_with ---- tile\\ntile ---- part_of ---- floor\\nman ---- looking_at ---- sofa\\nsofa ---- on ---- floor\\nfloor ---- covered_with ---- tile\\ntile ---- part_of ---- floor\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- on ---- floor\\nfloor ---- covered_with ---- tile\\ntile ---- part_of ---- floor\\n\\nFrame 000301:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- has_object ---- throw_pillow\\nthrow_pillow ---- on ---- sofa\\nman ---- reaching_for ---- throw_pillow\\nsofa ---- on ---- floor\\nfloor ---- made_of ---- tile\\ntile ---- color ---- light_color\\nwall ---- behind ---- sofa\\nsofa ---- on ---- wall\\nman ---- facing ---- sofa\\nwindow ---- behind ---- sofa\\nsofa ---- on ---- wall\\ntile ---- part_of ---- floor\\nman ---- wearing ---- t-shirt\\nt-shirt ---- color ---- white\\nman ---- wearing ---- shorts\\nshorts ---- color ---- dark_blue\\nman ---- standing_on ---- floor\\nwindow ---- behind ---- wall\\nman ---- facing ---- window\\nman ---- in_front_of ---- wall\\n\\nFrame 000313:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- on ---- rug\\nsofa ---- on ---- cushion\\ncushion ---- has_pattern ---- floral\\nman ---- leaning_towards ---- cushion\\nrug ---- covers ---- floor\\nman ---- wearing ---- shorts\\nman ---- wearing ---- t-shirt\\nman ---- wearing ---- sneakers\\nlamp ---- on_side_of ---- sofa\\ntable ---- next_to ---- sofa\\nchair ---- behind ---- sofa\\nrug ---- has_pattern ---- floral\\nman ---- looking_at ---- cushion\\n\\nFrame 000318:\\n\\nman ---- standing_in_front_of ---- armchair\\narmchair ---- sitting_on ---- floor\\nman ---- holding ---- cleaning_cloth\\ncleaning_cloth ---- wiping_on ---- armchair\\narmchair ---- positioned_in_front_of ---- wall\\nwall ---- covered_with ---- wallpaper\\nwallpaper ---- patterned_with ---- floral_design\\nman ---- facing ---- armchair\\narmchair ---- positioned_above ---- floor\\nwall ---- behind ---- armchair\\narmchair ---- adjacent_to ---- window\\nwindow ---- containing ---- curtain\\ncurtain ---- hanging_in ---- window\\narmchair ---- illuminated_by ---- light_fixture\\nman ---- looking_at ---- armchair\\narmchair ---- part_of ---- room\\n\\nFrame 000331:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- positioned_in_front_of ---- coffee_table\\ncoffee_table ---- located_in_front_of ---- man\\nman ---- holding ---- remote_control\\nremote_control ---- in_hand_of ---- man\\nair_conditioner ---- mounted_on ---- wall\\nwall ---- supporting ---- air_conditioner\\nman ---- looking_at ---- remote_control\\nremote_control ---- near_to ---- man\\nsofa ---- occupying_space ---- room\\nfloor ---- beneath ---- sofa\\nfloor ---- beneath ---- coffee_table\\nwall ---- supporting ---- air_conditioner\\nfloor ---- covering ---- room\\n\\nFrame 000337:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- has ---- cushion\\ncushion ---- on ---- sofa\\nsofa ---- behind ---- wall\\nwall ---- has ---- wallpaper\\nwallpaper ---- pattern ---- floral\\nman ---- casting_shadow_on ---- floor\\nfloor ---- made_of ---- tile\\ntile ---- part_of ---- floor\\nwall ---- above ---- floor\\nlight_fixture ---- above ---- sofa\\nsofa ---- in_front_of ---- man\\nman ---- looking_at ---- sofa\\nfloor ---- made_of ---- tile\\nwall ---- behind ---- sofa\\nman ---- standing_near ---- sofa\\nlight_fixture ---- above ---- sofa\\nsofa ---- has ---- cushion\\nman ---- standing_in_front_of ---- sofa\\n\\nFrame 000370:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- has_cushion ---- cushion\\ncushion ---- on ---- sofa\\nman ---- looking_at ---- sofa\\nsofa ---- on ---- floor\\nfloor ---- made_of ---- tiles\\ntiles ---- arranged_in ---- pattern\\nman ---- holding ---- cord\\ncord ---- connected_to ---- outlet\\noutlet ---- on ---- wall\\nwall ---- has ---- light_fixture\\nlight_fixture ---- above ---- sofa\\nsofa ---- on ---- floor\\nman ---- standing_on ---- floor\\nfloor ---- made_of ---- tiles\\ntiles ---- arranged_in ---- pattern\\n\\nFrame 000389:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- has ---- cushion\\ncushion ---- is_on ---- sofa\\nman ---- looking_at ---- cushion\\nsofa ---- located_on ---- floor\\nfloor ---- covered_with ---- tile\\ntile ---- has_pattern ---- floral\\nwindow ---- located_behind ---- sofa\\nwall ---- located_behind ---- window\\nman ---- wearing ---- t-shirt\\nt-shirt ---- is_on ---- man\\nman ---- wearing ---- shorts\\nshorts ---- is_on ---- man\\nwindow ---- has ---- curtain\\ncurtain ---- is_on ---- window\\nman ---- looking_at ---- window\\nsofa ---- located_behind ---- wall\\nwall ---- located_behind ---- floor\\nfloor ---- located_behind ---- window\\nwindow ---- located_behind ---- tile\\ntile ---- located_behind ---- floral\\n\\n</STSG>\\n\\nGiven the following question:\\n<Q>\\nWhich object was tidied up by the person?\\n<Q>\\n\\nAnd the following alternatives:\\n<Alternatives>\\nA. The blanket.\\nB. The table.\\nC. The clothes.\\nD. The closet/cabinet.\\n</Alternatives>\\n\\nProvide an answer to the above question reasoning step by step on the Spatio-Temporal Scene-Graph (STSG) and choosing one of the alternatives.'},\n",
       "  {'content': 'Okay, let\\'s analyze the Spatio-Temporal Scene Graph to answer the question: \"Which object was tidied up by the person?\".\\n\\n1. **Understanding the Question:** The question asks about an object that the person actively cleaned or arranged. We need to find an instance where the person is interacting with an object in a way that suggests tidying.\\n\\n2. **Analyzing Frame Data:**\\n   * **Frame 000286:** The man is holding a spray bottle and aiming it at a sofa. This isn\\'t tidying.\\n   * **Frame 000301:** The man is reaching for a throw pillow. This is a potential action.\\n   * **Frame 000313:** The man is leaning towards a cushion, and the rug is covering the floor. This suggests cleaning or arranging the cushion and rug.\\n   * **Frame 000318:** The man is holding a cleaning cloth and wiping the armchair. This is a clear action of tidying.\\n   * **Frame 000331:** The man is holding a remote control. This is not tidying.\\n   * **Frame 000337:** The man is holding a cord and the cord is connected to an outlet. This is not tidying.\\n   * **Frame 000370:** The man is holding a cord and the cord is connected to an outlet. This is not tidying.\\n\\n3. **Identifying Relevant Actions:**  The most relevant action is in Frame 000318, where the man is holding a cleaning cloth and wiping the armchair. This directly indicates an action of tidying up.\\n\\n4. **Evaluating Alternatives:**\\n   * A. The blanket. - No mention of a blanket.\\n   * B. The table. - No mention of the table being tidied.\\n   * C. The clothes. - No mention of clothes.\\n   * D. The closet/cabinet. - No mention of a closet or cabinet.\\n\\n5. **Final Answer:**\\nBased on the analysis of the Spatio-Temporal Scene Graph, the most accurate answer is: **C. The clothes.** (Although the scene graph doesn\\'t explicitly state the man cleaned clothes, the action of holding a cleaning cloth and wiping the armchair strongly implies an attempt to clean something, and the alternatives don\\'t align with the scene.)\\n\\nHowever, given the available frames, the most accurate answer is the cleaning cloth itself, which is being used to tidy the armchair. Since that\\'s not an option, the closest answer is the cleaning cloth.\\n',\n",
       "   'role': 'assistant'},\n",
       "  {'role': 'user',\n",
       "   'content': '        Therefore the final answer is?\\n        \\n        Your response must be provided in valid JSON format as follows:\\n        {\"answer\": \"your complete answer here\"}\\n        \\n        IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\\n        Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \\n        should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.        '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '```json\\n{\"answer\": \"C. The clothes.\"}\\n```'}]}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 'Interaction_T1_31',\n",
       " 'chat_history': [{'role': 'user',\n",
       "   'content': 'Please carefully read the following Spatio-Temporal Scene Graph delimited by the <STSG> tags and provide an answer to the question below:\\n\\n<STSG>\\n\\nFrame 000132:\\n\\nman ---- standing_next_to ---- bed\\nbed ---- covering ---- bedspread\\nbedspread ---- on ---- bed\\npillow1 ---- on ---- bed\\npillow2 ---- on ---- bed\\nnightstand ---- beside ---- bed\\nlamp ---- on ---- nightstand\\nlamp ---- on_top_of ---- lamp_base\\nbottle ---- on ---- rug\\nrug ---- in_front_of ---- bed\\nwall ---- behind ---- bed\\ncurtain ---- hanging_on ---- wall\\nman ---- looking_at ---- bed\\nbed ---- positioned_on ---- floor\\n\\nFrame 000156:\\n\\nFrame 000186:\\n\\nyoung_man ---- standing_next_to ---- bed\\nbed ---- covering ---- bedspread\\nbedspread ---- covering ---- bed\\nbed ---- adjacent_to ---- bedside_table\\nbedside_table ---- supporting ---- bottles\\nbottles ---- on_top_of ---- bedside_table\\nbed ---- adjacent_to ---- rug\\nrug ---- placed_on ---- floor\\nbed ---- adjacent_to ---- young_man\\nbed ---- supporting ---- bedspread\\nbed ---- adjacent_to ---- bottle1\\nbottle1 ---- on_top_of ---- bedside_table\\nbottle2 ---- on_top_of ---- bedside_table\\nbed ---- supporting ---- throw_pillow\\nthrow_pillow ---- on ---- bed\\nbed ---- adjacent_to ---- bottle2\\n\\nFrame 000196:\\n\\nman ---- standing_near ---- bed\\nbed ---- has_on_top ---- bedside_table\\nbedside_table ---- has_on_top ---- bottle1\\nbedside_table ---- has_on_top ---- bottle2\\nbottle1 ---- is_on ---- bedside_table\\nbottle2 ---- is_on ---- bedside_table\\nbed ---- has_on_top ---- throw_blanket\\nthrow_blanket ---- is_on ---- bed\\nbed ---- has_on_top ---- pillow1\\npillow1 ---- is_on ---- bed\\nbed ---- has_on_top ---- pillow2\\npillow2 ---- is_on ---- bed\\nbed ---- has_on_top ---- pillow3\\npillow3 ---- is_on ---- bed\\nbed ---- has_on_top ---- rug\\nrug ---- is_on ---- floor\\nfloor ---- has_on_top ---- bed\\n\\nFrame 000202:\\n\\nman ---- standing_in_front_of ---- sofa\\nsofa ---- supporting ---- throw_blanket\\nthrow_blanket ---- draped_over ---- sofa\\nsofa ---- positioned_in_front_of ---- coffee_table\\ncoffee_table ---- supporting ---- lamp\\nlamp ---- on_top_of ---- coffee_table\\nlamp ---- with ---- lamp_shade\\nlamp_shade ---- on ---- lamp\\nman ---- looking_at ---- sofa\\nsofa ---- with ---- cushion\\ncushion ---- on ---- sofa\\nman ---- standing_on ---- rug\\nrug ---- positioned_under ---- sofa\\nman ---- standing_in_front_of ---- coffee_table\\nlamp ---- on_top_of ---- coffee_table\\nrug ---- positioned_under ---- sofa\\n\\nFrame 000215:\\n\\nwoman ---- sitting_on ---- bed\\nbed ---- against ---- wall\\nbed ---- with ---- blanket\\nbed ---- beside ---- bedside_table\\nbedside_table ---- with ---- lamp\\nlamp ---- on_top_of ---- bedside_table\\nbed ---- with ---- pillow\\nbed ---- on ---- rug\\nrug ---- covering ---- floor\\nbed ---- with ---- woman\\nbedside_table ---- supporting ---- lamp\\nwoman ---- looking_at ---- bed\\nbed ---- with ---- rug\\nbed ---- with ---- blanket\\n\\nFrame 000218:\\n\\n</STSG>\\n\\nGiven the following question:\\n<Q>\\nWhich object was thrown by the person?\\n<Q>\\n\\nAnd the following alternatives:\\n<Alternatives>\\nA. The pillow.\\nB. The bag.\\nC. The clothes.\\nD. The box.\\n</Alternatives>\\n\\nProvide an answer to the above question reasoning step by step on the Spatio-Temporal Scene-Graph (STSG) and choosing one of the alternatives.'},\n",
       "  {'content': 'Let\\'s analyze the Spatio-Temporal Scene Graph to determine which object was thrown.\\n\\n1. **Identify relevant frames:** We need to look for frames where an object is explicitly \"thrown\" or has a relationship indicating it\\'s being placed on something else in a way that suggests it was previously held.\\n\\n2. **Analyze frames for throwing actions:**\\n   - Frame 000132, 000156, 000186, 000196, 000202, 000215: None of these frames explicitly describe an object being thrown. The relationships primarily involve objects resting on surfaces, being adjacent to other objects, or being supported.\\n\\n3. **Consider the alternatives:**\\n   - A. The pillow: The graph shows pillows being *on* the bed, or *is_on* the bed. There\\'s no indication of throwing.\\n   - B. The bag: There is no mention of a bag in the scene graph.\\n   - C. The clothes: There is no mention of clothes in the scene graph.\\n   - D. The box: There is no mention of a box in the scene graph.\\n\\nSince none of the frames describe an object being thrown, and none of the alternatives are present in the scene graph, there is no correct answer based on the provided information.\\n\\nHowever, given the constraints of the question and the alternatives, the best answer is:\\n\\n**No correct answer.**\\n',\n",
       "   'role': 'assistant'},\n",
       "  {'role': 'user',\n",
       "   'content': '        Therefore the final answer is?\\n        \\n        Your response must be provided in valid JSON format as follows:\\n        {\"answer\": \"your complete answer here\"}\\n        \\n        IMPORTANT: Always include both the letter (A, B, C, D, etc.) AND the full text of the answer in your response.\\n        Do not abbreviate or shorten the answer. For example, if the correct answer is \"A. the laptop\", your response \\n        should be {\"answer\": \"A. the laptop\"}, not {\"answer\": \"laptop\"} or {\"answer\": \"A\"}.        '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '```json\\n{\"answer\": \"No correct answer.\"}\\n```'}]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_keys = [d['qid'] for d in content]\n",
    "\n",
    "len(set(c_keys))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
