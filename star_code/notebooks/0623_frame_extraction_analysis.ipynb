{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import re\n",
    "import os, sys, pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import subprocess\n",
    "\n",
    "WORK_DIR = Path.cwd().parent\n",
    "sys.path.append(str(WORK_DIR))\n",
    "\n",
    "from src import video_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAR_TRAIN = WORK_DIR / \"data/datasets/STAR/STAR_annotations/STAR_train.json\"\n",
    "STAR_VAL = WORK_DIR / \"data/datasets/STAR/STAR_annotations/STAR_val.json\"\n",
    "STAR_TEST = WORK_DIR / \"data/datasets/STAR/STAR_annotations/STAR_test.json\"\n",
    "STAR_SMALL = WORK_DIR / \"data/datasets/STAR/STAR_annotations/STAR_val_small_1000.json\"\n",
    "\n",
    "RAW_FRAMES_DIR = WORK_DIR / \"data/datasets/action-genome/frames\"\n",
    "KEYFRAMES_INFO_PATH = WORK_DIR / \"data/datasets/STAR/Video_Keyframe_IDs.csv\"\n",
    "\n",
    "RAW_VIDEO_DIR = Path(WORK_DIR / 'data/datasets/action-genome/Charades_v1_480/')\n",
    "SAVE_VIDEO_DIR = Path(WORK_DIR / \"experiments/video_dump\")\n",
    "ANNOTATION_DIR = WORK_DIR / 'src/STAR_utils/annotations/STAR_classes/'\n",
    "\n",
    "with open(ANNOTATION_DIR / 'video_fps','rb') as f: \n",
    "    fps_info = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(STAR_TRAIN) as f:\n",
    "    star_train_df = pd.read_json(f)\n",
    "\n",
    "with open(STAR_VAL) as f:\n",
    "    star_val_df = pd.read_json(f)\n",
    "\n",
    "star_train_val_df = pd.concat([star_train_df, star_val_df], ignore_index=True)\n",
    "\n",
    "with open(STAR_TEST) as f:\n",
    "    star_test_df = pd.read_json(f)\n",
    "\n",
    "star_all_df = pd.concat([star_train_val_df, star_test_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique video ID counts:\n",
      "  Train         : 3032\n",
      "  Train + Val   : 3946\n",
      "  Test          : 955\n",
      "  All           : 4901\n",
      "\n",
      "Intersection metrics:\n",
      "  Train ∩ Val        : 0\n",
      "  Train+Val ∩ Test   : 0\n"
     ]
    }
   ],
   "source": [
    "# Convert video_id columns to sets for comparison\n",
    "train_ids      = set(star_train_df['video_id'])\n",
    "val_ids        = set(star_val_df['video_id'])\n",
    "train_val_ids  = set(star_train_val_df['video_id'])\n",
    "test_ids       = set(star_test_df['video_id'])\n",
    "all_ids        = set(star_all_df['video_id'])\n",
    "\n",
    "# 1. Print unique counts\n",
    "print(\"Unique video ID counts:\")\n",
    "print(f\"  Train         : {len(train_ids)}\")\n",
    "print(f\"  Train + Val   : {len(train_val_ids)}\")\n",
    "print(f\"  Test          : {len(test_ids)}\")\n",
    "print(f\"  All           : {len(all_ids)}\")\n",
    "\n",
    "# 2. Compute intersections\n",
    "train_val_intersection      = train_ids & val_ids\n",
    "train_test_intersection     = train_ids & test_ids\n",
    "val_test_intersection       = val_ids & test_ids\n",
    "train_val_test_intersection = train_val_ids & test_ids\n",
    "\n",
    "# 3. Compute exclusives\n",
    "train_exclusive_vs_val      = train_ids - val_ids\n",
    "val_exclusive_vs_train      = val_ids - train_ids\n",
    "test_exclusive_vs_train     = test_ids - train_ids\n",
    "test_exclusive_vs_val       = test_ids - val_ids\n",
    "test_exclusive_vs_train_val = test_ids - train_val_ids\n",
    "\n",
    "\n",
    "print(\"\\nIntersection metrics:\")\n",
    "print(f\"  Train ∩ Val        : {len(train_val_intersection)}\")\n",
    "print(f\"  Train+Val ∩ Test   : {len(train_val_test_intersection)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAR uses 4901 frames but the fps file has info for 9848 videos, which is the number of videos contained in the videos directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 9848 entries, BE43L.mp4 to S8PVE.mp4\n",
      "Series name: None\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "9848 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 153.9+ KB\n"
     ]
    }
   ],
   "source": [
    "fps_info = pd.Series(fps_info)\n",
    "fps_info.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9848"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(RAW_VIDEO_DIR.iterdir()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9601"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_frames = [dir.stem for dir in RAW_FRAMES_DIR.iterdir()]\n",
    "len(raw_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all the videos have the frame extracted from the ActionGenome toolkit.  \n",
    "Let's see if the videos used in STAR are correctly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(star_all_df['video_id'].isin(raw_frames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's review the frame dumping tool from Action Genome used in STAR:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def dump_frames(args):\n",
    "    video_dir = args.video_dir\n",
    "    frame_dir = args.frame_dir\n",
    "    annotation_dir = args.annotation_dir\n",
    "    all_frames = args.all_frames\n",
    "\n",
    "    # Load the list of annotated frames\n",
    "    frame_list = []\n",
    "    with open(os.path.join(annotation_dir, 'frame_list.txt'), 'r') as f:\n",
    "        for frame in f:\n",
    "            frame_list.append(frame.rstrip('\\n'))\n",
    "\n",
    "    # Create video to frames mapping\n",
    "    video2frames = {}\n",
    "    for path in frame_list:\n",
    "        video, frame = path.split('/')\n",
    "        if video not in video2frames:\n",
    "            video2frames[video] = []\n",
    "        video2frames[video].append(frame)\n",
    "\n",
    "    # For each video, dump frames.\n",
    "    for v in tqdm(video2frames):\n",
    "        curr_frame_dir = os.path.join(frame_dir, v)\n",
    "        if not os.path.exists(curr_frame_dir):\n",
    "            os.makedirs(curr_frame_dir)\n",
    "            # Use ffmpeg to extract frames. Different versions of ffmpeg may generate slightly different frames.\n",
    "            # We used ffmpeg 2.8.15 to dump our frames.\n",
    "            # Note that the frames are extracted according to their original video FPS, which is not always 24.\n",
    "            # Therefore, our frame indices are different from Charades extracted frames' indices.\n",
    "            os.system('ffmpeg -loglevel panic -i %s/%s %s/%%06d.png' % (video_dir, v, curr_frame_dir))\n",
    "\n",
    "            # if not keeping all frames, only keep the annotated frames included in frame_list.txt\n",
    "            if not all_frames:\n",
    "                keep_frames = video2frames[v]\n",
    "                frames_to_delete = set(os.listdir(curr_frame_dir)) - set(keep_frames)\n",
    "                for frame in frames_to_delete:\n",
    "                    os.remove(os.path.join(curr_frame_dir, frame))\n",
    "        else:\n",
    "            warnings.warn('Frame directory %s already exists. Skipping dumping into this directory.' % curr_frame_dir,\n",
    "                          RuntimeWarning)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Dump frames\")\n",
    "    parser.add_argument(\"--video_dir\", default=\"dataset/ag/videos\",\n",
    "                        help=\"Folder containing Charades videos.\")\n",
    "    parser.add_argument(\"--frame_dir\", default=\"dataset/ag/frames\",\n",
    "                        help=\"Root folder containing frames to be dumped.\")\n",
    "    parser.add_argument(\"--annotation_dir\", default=\"dataset/ag/annotations\",\n",
    "                        help=(\"Folder containing annotation files, including object_bbox_and_relationship.pkl, \"\n",
    "                              \"person_bbox.pkl and frame_list.txt.\"))\n",
    "    parser.add_argument(\"--all_frames\", action=\"store_true\",\n",
    "                        help=\"Set if you want to dump all frames, rather than the frames listed in frame_list.txt\")\n",
    "    args = parser.parse_args()\n",
    "    dump_frames(args)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The ffmpeg command**\n",
    "\n",
    "```bash\n",
    "ffmpeg -loglevel panic -i %s/%s %s/%%06d.png' % (video_dir, v, curr_frame_dir)\n",
    "```\n",
    "\n",
    "- `-loglevel panic`   : Only show fatal errors which could lead the process to crash, such as an assertion failure.\n",
    "- `-i {video_dir}/{v}`: specifies the input video file.\n",
    "- `%06d.png`          : Extracts the frames of the video at native fps and saves them with the specified name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BE43L.mp4    29.970030\n",
       "LHPQS.mp4    59.940060\n",
       "OTL44.mp4    15.076000\n",
       "D548M.mp4    30.000000\n",
       "4ZNNP.mp4    30.000000\n",
       "               ...    \n",
       "GIIMN.mp4    30.000000\n",
       "2J4MA.mp4    14.995002\n",
       "4GWNV.mp4    15.000000\n",
       "AGWQA.mp4    29.970030\n",
       "S8PVE.mp4    29.970030\n",
       "Length: 9848, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lusha/star_code/data/datasets/action-genome/Charades_v1_480/D548M.mp4'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = str(RAW_VIDEO_DIR / \"D548M.mp4\")\n",
    "video_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30.733333'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_tools.get_video_stream_info(video_path)['duration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codec_name=h264\n",
      "width=480\n",
      "height=360\n",
      "r_frame_rate=30/1\n",
      "avg_frame_rate=30/1\n",
      "duration=30.733333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run([\n",
    "    \"ffprobe\",\n",
    "    \"-v\", \"error\",\n",
    "    \"-select_streams\", \"v:0\",\n",
    "    \"-show_entries\", \"stream=codec_name,width,height,r_frame_rate,avg_frame_rate,duration\",\n",
    "    \"-of\", \"default=noprint_wrappers=1\",\n",
    "    \"-i\", video_path\n",
    "],\n",
    "capture_output=True,  # capture stdout & stderr\n",
    "text=True,            # return strings instead of bytes\n",
    "check=True            # raise CalledProcessError on non-zero exit\n",
    ")\n",
    "\n",
    "print(result.stdout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
