{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lusha\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "WORK_DIR = Path.cwd().parent\n",
    "\n",
    "sys.path.append(str(WORK_DIR))\n",
    "print(WORK_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from star_code.src.datasets import CVRRDataset, JudgeDataset\n",
    "from star_code.src.prompt_formatters import OpenEndedPrompt, LlmAsJudgePrompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval on CVRR\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- model: gemma3:4b-it-qat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA on generated graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Video Question-Answering System Prompt\n",
      "\n",
      "You are an AI assistant specialized in answering questions about videos based on their scene graph representations. Instead of receiving raw video data, you will be provided with structured scene graph information that captures the key visual and temporal elements of the video content.\n",
      "\n",
      "## Input Format\n",
      "\n",
      "You will receive two inputs:\n",
      "1. **Question**: An open-ended question about the video content\n",
      "2. **Scene Graph Representation**: A structured representation of the video containing:\n",
      "\n",
      "### Scene Graph Structure\n",
      "- **Objects**: Entities present in the video (people, animals, objects, etc.)\n",
      "- **Attributes**: Properties of objects (color, size, position, state, etc.)\n",
      "- **Relationships**: Spatial and semantic connections between objects\n",
      "- **Temporal Information**: How objects and relationships change over time\n",
      "- **Actions/Events**: Activities and interactions occurring in the video\n",
      "- **Scene Context**: Location, setting, environmental details\n",
      "\n",
      "### Example Scene Graph Format\n",
      "```\n",
      "Timestamp: [0-5s]\n",
      "Objects: [person_1, person_2, ball, grass, goal_post]\n",
      "Attributes: \n",
      "  - person_1: {color: \"red_shirt\", position: \"left_side\", state: \"running\"}\n",
      "  - ball: {color: \"white\", position: \"center\", state: \"moving\"}\n",
      "Relationships:\n",
      "  - person_1 → chasing → ball\n",
      "  - ball → near → person_2\n",
      "Actions: [kick, run, pass]\n",
      "Scene: outdoor_soccer_field\n",
      "```\n",
      "\n",
      "## Task Instructions\n",
      "\n",
      "1. **Analyze the Scene Graph**: Carefully examine all provided temporal segments, objects, attributes, relationships, and actions.\n",
      "\n",
      "2. **Answer Comprehensively**: Provide detailed, accurate answers based solely on the information present in the scene graph representation.\n",
      "\n",
      "3. **Handle Different Question Types**:\n",
      "   - **What questions**: Identify objects, actions, or attributes\n",
      "   - **Where questions**: Use spatial relationships and scene context\n",
      "   - **When questions**: Reference temporal information and timestamps\n",
      "   - **Who questions**: Identify people and their characteristics\n",
      "   - **How questions**: Describe processes, methods, or sequences of actions\n",
      "   - **Why questions**: Infer motivations from visible actions and context\n",
      "\n",
      "4. **Temporal Reasoning**: When answering questions about sequences, timing, or changes, reference specific timestamps and describe how elements evolve over time.\n",
      "\n",
      "5. **Relationship Analysis**: Utilize the relationship information to understand interactions, spatial arrangements, and causal connections.\n",
      "\n",
      "6. **Uncertainty Handling**: If the scene graph doesn't contain sufficient information to answer a question definitively, clearly state what information is available and what cannot be determined.\n",
      "\n",
      "## Response Guidelines\n",
      "\n",
      "- **Be Specific**: Reference exact timestamps, object attributes, and relationships when relevant\n",
      "- **Be Accurate**: Only make claims supported by the scene graph data\n",
      "- **Be Complete**: Address all aspects of multi-part questions\n",
      "- **Be Clear**: Use natural language while incorporating technical details when necessary\n",
      "- **Acknowledge Limitations**: If certain visual details are not captured in the scene graph, mention this limitation\n",
      "\n",
      "## Example Response Structure\n",
      "\n",
      "**Question**: \"What is the person in the red shirt doing at the beginning of the video?\"\n",
      "\n",
      "**Response**: \"Based on the scene graph representation, during the first 5 seconds (timestamp 0-5s), person_1 is wearing a red shirt and is located on the left side of what appears to be an outdoor soccer field. The person is in a 'running' state and has a 'chasing' relationship with a white ball positioned in the center of the scene. This indicates that the person in the red shirt is running while chasing the ball at the beginning of the video.\"\n",
      "\n",
      "## Important Notes\n",
      "\n",
      "- Focus on observable elements captured in the scene graph rather than making assumptions about elements not explicitly represented\n",
      "- When temporal information spans multiple timestamps, provide a chronological description of changes\n",
      "- Use the relationship data to understand complex interactions and spatial arrangements\n",
      "- Consider both direct attributes and inferred information from relationships and actions\n",
      "\n",
      "Your goal is to provide accurate, comprehensive answers that demonstrate understanding of the video content through its structured scene graph representation.\n"
     ]
    }
   ],
   "source": [
    "with open(WORK_DIR / 'cvrr/sys_prompt.txt', 'r') as f:\n",
    "    sys_prompt = f.read()\n",
    "\n",
    "print(sys_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Video Question-Answering User Prompt Template\n",
      "\n",
      "## Question\n",
      "{question}\n",
      "\n",
      "## Spatio-Temporal Scene Graph Representation\n",
      "{stsg}\n",
      "\n",
      "---\n",
      "\n",
      "Please analyze the provided scene graph representation and answer the question based on the visual and temporal information contained within it.\n"
     ]
    }
   ],
   "source": [
    "with open(WORK_DIR / 'cvrr/user_prompt.txt', 'r') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "print(user_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the ground truth from the `STAR_QA_question_and_stsg_val.json` file where we extracted QA and spatio-temporal scene graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "========================================\n",
      "QA File: cvrr_val_updated.json\n",
      "Number of QA samples: 2400\n",
      "QA sample keys: dimension_name, subset, question_id, question, video_id, answer\n",
      "\n",
      "STSG File: generated_stsg_cvrr.json\n",
      "Number of unique video IDs with STSG: 193\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompt_formatter = OpenEndedPrompt(user_prompt)\n",
    "qa_cvrr_dataset = CVRRDataset(\n",
    "    qa_file_path=WORK_DIR/\"cvrr/cvrr_val_updated.json\",\n",
    "    prompt_formatter=user_prompt_formatter,\n",
    "    stsg_file_path=WORK_DIR/\"cvrr/generated_stsg_cvrr.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension_name': 'Continuity and Object Instance Count',\n",
       " 'subset': 'continuity_and_object_instance_count',\n",
       " 'question_id': '2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0',\n",
       " 'question': 'How many times is the golden hollow sphere gets covered by other objects?',\n",
       " 'video_id': 'continuity_and_object_instance_count_183',\n",
       " 'answer': 'The golden hollow sphere is covered two times by other objects.',\n",
       " 'stsg': '\\nFrame 0:\\n\\n\\npurple_cube ---- above ---- yellow_sphere\\npurple_cube ---- adjacent_to ---- green_cone\\npurple_cube ---- adjacent_to ---- red_cone\\ngreen_cone ---- to_the_left_of ---- purple_cube\\nred_cone ---- to_the_right_of ---- purple_cube\\nyellow_sphere ---- below ---- purple_cube\\ngreen_cone ---- positioned_near ---- purple_cube\\nred_cone ---- positioned_near ---- purple_cube\\nyellow_sphere ---- directly_under ---- purple_cube\\npurple_cube ---- supporting ---- yellow_sphere\\n\\nFrame 1:\\n\\n\\nred_sphere ---- above ---- green_cone\\ngreen_cone ---- above ---- purple_cube\\npurple_cube ---- on ---- surface\\nred_sphere ---- above ---- green_cone\\ngreen_cone ---- looking_at ---- purple_cube\\nred_sphere ---- looking_at ---- green_cone\\npurple_cube ---- on_top_of ---- surface\\ngreen_cone ---- attached_to ---- red_sphere\\nsurface ---- supporting ---- purple_cube\\ngreen_cone ---- positioned_above ---- purple_cube\\nred_sphere ---- positioned_above ---- green_cone\\n\\nFrame 2:\\n\\nred_sphere ---- above ---- purple_cube\\npurple_cube ---- on ---- white_surface\\ngreen_cylinder ---- to_the_right_of ---- purple_cube\\nwhite_surface ---- supporting ---- purple_cube\\nred_sphere ---- looking_at ---- purple_cube\\npurple_cube ---- positioned_on ---- white_surface\\ngreen_cylinder ---- adjacent_to ---- purple_cube\\nwhite_surface ---- containing ---- red_sphere\\nred_sphere ---- positioned_above ---- purple_cube\\ngreen_cylinder ---- near ---- purple_cube\\npurple_cube ---- centered_on ---- white_surface\\n\\nFrame 3:\\n\\npurple_cube ---- sitting_on ---- gray_table\\ngreen_cone ---- positioned_behind ---- purple_cube\\ngray_table ---- supporting ---- purple_cube\\ngray_table ---- adjacent_to ---- gray_chair\\ngray_chair ---- positioned_next_to ---- gray_table\\npurple_cube ---- placed_on ---- gray_table\\ngreen_cone ---- located_behind ---- purple_cube\\ngray_table ---- resting_on ---- gray_floor\\ngray_floor ---- supporting ---- gray_table\\npurple_cube ---- part_of ---- scene\\ngreen_cone ---- part_of ---- scene\\ngray_table ---- part_of ---- scene\\ngray_chair ---- part_of ---- scene\\n\\nFrame 4:\\n\\ngreen_cylinder ---- supporting ---- purple_cube\\npurple_cube ---- resting_on ---- green_cylinder\\ngreen_cylinder ---- positioned_on ---- gray_background\\ngray_background ---- behind ---- green_cylinder\\npurple_cube ---- above ---- green_cylinder\\ngreen_cylinder ---- positioned_above ---- gray_background\\npurple_cube ---- adjacent_to ---- green_cylinder\\ngreen_cylinder ---- centered_on ---- purple_cube\\npurple_cube ---- reflecting_off ---- green_cylinder\\ngray_background ---- providing_backdrop_for ---- green_cylinder\\npurple_cube ---- occupying_space_above ---- green_cylinder\\n',\n",
       " 'qid': '2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0',\n",
       " 'prompt': '# Video Question-Answering User Prompt Template\\n\\n## Question\\nHow many times is the golden hollow sphere gets covered by other objects?\\n\\n## Spatio-Temporal Scene Graph Representation\\n\\nFrame 0:\\n\\n\\npurple_cube ---- above ---- yellow_sphere\\npurple_cube ---- adjacent_to ---- green_cone\\npurple_cube ---- adjacent_to ---- red_cone\\ngreen_cone ---- to_the_left_of ---- purple_cube\\nred_cone ---- to_the_right_of ---- purple_cube\\nyellow_sphere ---- below ---- purple_cube\\ngreen_cone ---- positioned_near ---- purple_cube\\nred_cone ---- positioned_near ---- purple_cube\\nyellow_sphere ---- directly_under ---- purple_cube\\npurple_cube ---- supporting ---- yellow_sphere\\n\\nFrame 1:\\n\\n\\nred_sphere ---- above ---- green_cone\\ngreen_cone ---- above ---- purple_cube\\npurple_cube ---- on ---- surface\\nred_sphere ---- above ---- green_cone\\ngreen_cone ---- looking_at ---- purple_cube\\nred_sphere ---- looking_at ---- green_cone\\npurple_cube ---- on_top_of ---- surface\\ngreen_cone ---- attached_to ---- red_sphere\\nsurface ---- supporting ---- purple_cube\\ngreen_cone ---- positioned_above ---- purple_cube\\nred_sphere ---- positioned_above ---- green_cone\\n\\nFrame 2:\\n\\nred_sphere ---- above ---- purple_cube\\npurple_cube ---- on ---- white_surface\\ngreen_cylinder ---- to_the_right_of ---- purple_cube\\nwhite_surface ---- supporting ---- purple_cube\\nred_sphere ---- looking_at ---- purple_cube\\npurple_cube ---- positioned_on ---- white_surface\\ngreen_cylinder ---- adjacent_to ---- purple_cube\\nwhite_surface ---- containing ---- red_sphere\\nred_sphere ---- positioned_above ---- purple_cube\\ngreen_cylinder ---- near ---- purple_cube\\npurple_cube ---- centered_on ---- white_surface\\n\\nFrame 3:\\n\\npurple_cube ---- sitting_on ---- gray_table\\ngreen_cone ---- positioned_behind ---- purple_cube\\ngray_table ---- supporting ---- purple_cube\\ngray_table ---- adjacent_to ---- gray_chair\\ngray_chair ---- positioned_next_to ---- gray_table\\npurple_cube ---- placed_on ---- gray_table\\ngreen_cone ---- located_behind ---- purple_cube\\ngray_table ---- resting_on ---- gray_floor\\ngray_floor ---- supporting ---- gray_table\\npurple_cube ---- part_of ---- scene\\ngreen_cone ---- part_of ---- scene\\ngray_table ---- part_of ---- scene\\ngray_chair ---- part_of ---- scene\\n\\nFrame 4:\\n\\ngreen_cylinder ---- supporting ---- purple_cube\\npurple_cube ---- resting_on ---- green_cylinder\\ngreen_cylinder ---- positioned_on ---- gray_background\\ngray_background ---- behind ---- green_cylinder\\npurple_cube ---- above ---- green_cylinder\\ngreen_cylinder ---- positioned_above ---- gray_background\\npurple_cube ---- adjacent_to ---- green_cylinder\\ngreen_cylinder ---- centered_on ---- purple_cube\\npurple_cube ---- reflecting_off ---- green_cylinder\\ngray_background ---- providing_backdrop_for ---- green_cylinder\\npurple_cube ---- occupying_space_above ---- green_cylinder\\n\\n\\n---\\n\\nPlease analyze the provided scene graph representation and answer the question based on the visual and temporal information contained within it.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of entry\n",
    "qa_cvrr_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Video Question-Answering User Prompt Template\n",
      "\n",
      "## Question\n",
      "How many times is the golden hollow sphere gets covered by other objects?\n",
      "\n",
      "## Spatio-Temporal Scene Graph Representation\n",
      "\n",
      "Frame 0:\n",
      "\n",
      "\n",
      "purple_cube ---- above ---- yellow_sphere\n",
      "purple_cube ---- adjacent_to ---- green_cone\n",
      "purple_cube ---- adjacent_to ---- red_cone\n",
      "green_cone ---- to_the_left_of ---- purple_cube\n",
      "red_cone ---- to_the_right_of ---- purple_cube\n",
      "yellow_sphere ---- below ---- purple_cube\n",
      "green_cone ---- positioned_near ---- purple_cube\n",
      "red_cone ---- positioned_near ---- purple_cube\n",
      "yellow_sphere ---- directly_under ---- purple_cube\n",
      "purple_cube ---- supporting ---- yellow_sphere\n",
      "\n",
      "Frame 1:\n",
      "\n",
      "\n",
      "red_sphere ---- above ---- green_cone\n",
      "green_cone ---- above ---- purple_cube\n",
      "purple_cube ---- on ---- surface\n",
      "red_sphere ---- above ---- green_cone\n",
      "green_cone ---- looking_at ---- purple_cube\n",
      "red_sphere ---- looking_at ---- green_cone\n",
      "purple_cube ---- on_top_of ---- surface\n",
      "green_cone ---- attached_to ---- red_sphere\n",
      "surface ---- supporting ---- purple_cube\n",
      "green_cone ---- positioned_above ---- purple_cube\n",
      "red_sphere ---- positioned_above ---- green_cone\n",
      "\n",
      "Frame 2:\n",
      "\n",
      "red_sphere ---- above ---- purple_cube\n",
      "purple_cube ---- on ---- white_surface\n",
      "green_cylinder ---- to_the_right_of ---- purple_cube\n",
      "white_surface ---- supporting ---- purple_cube\n",
      "red_sphere ---- looking_at ---- purple_cube\n",
      "purple_cube ---- positioned_on ---- white_surface\n",
      "green_cylinder ---- adjacent_to ---- purple_cube\n",
      "white_surface ---- containing ---- red_sphere\n",
      "red_sphere ---- positioned_above ---- purple_cube\n",
      "green_cylinder ---- near ---- purple_cube\n",
      "purple_cube ---- centered_on ---- white_surface\n",
      "\n",
      "Frame 3:\n",
      "\n",
      "purple_cube ---- sitting_on ---- gray_table\n",
      "green_cone ---- positioned_behind ---- purple_cube\n",
      "gray_table ---- supporting ---- purple_cube\n",
      "gray_table ---- adjacent_to ---- gray_chair\n",
      "gray_chair ---- positioned_next_to ---- gray_table\n",
      "purple_cube ---- placed_on ---- gray_table\n",
      "green_cone ---- located_behind ---- purple_cube\n",
      "gray_table ---- resting_on ---- gray_floor\n",
      "gray_floor ---- supporting ---- gray_table\n",
      "purple_cube ---- part_of ---- scene\n",
      "green_cone ---- part_of ---- scene\n",
      "gray_table ---- part_of ---- scene\n",
      "gray_chair ---- part_of ---- scene\n",
      "\n",
      "Frame 4:\n",
      "\n",
      "green_cylinder ---- supporting ---- purple_cube\n",
      "purple_cube ---- resting_on ---- green_cylinder\n",
      "green_cylinder ---- positioned_on ---- gray_background\n",
      "gray_background ---- behind ---- green_cylinder\n",
      "purple_cube ---- above ---- green_cylinder\n",
      "green_cylinder ---- positioned_above ---- gray_background\n",
      "purple_cube ---- adjacent_to ---- green_cylinder\n",
      "green_cylinder ---- centered_on ---- purple_cube\n",
      "purple_cube ---- reflecting_off ---- green_cylinder\n",
      "gray_background ---- providing_backdrop_for ---- green_cylinder\n",
      "purple_cube ---- occupying_space_above ---- green_cylinder\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Please analyze the provided scene graph representation and answer the question based on the visual and temporal information contained within it.\n"
     ]
    }
   ],
   "source": [
    "print(qa_cvrr_dataset[0][\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0</th>\n",
       "      <td>The golden hollow sphere (referred to as purpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b27163c5-d341-475b-8517-54809872081a</th>\n",
       "      <td>Based on the provided scene graph representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9bce3140-e8e8-49dd-8574-5e961326fb16</th>\n",
       "      <td>Okay, let's analyze the scene graph and answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8df9fbe-07db-46ab-ba17-3713c1632dbd</th>\n",
       "      <td>The golden sphere (referred to as purple_cube ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01c30c62-f489-4246-af18-b7b538b4cb9d</th>\n",
       "      <td>Based on the provided scene graph representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073994c-e4ca-4592-b001-fe0a79ab0e3f</th>\n",
       "      <td>Based on the provided scene graph representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a158fb7-38cb-49b4-91e8-0cb63d6bf218</th>\n",
       "      <td>Okay, let's analyze the scene graph and answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247a493d-0d24-4f1b-bbf6-b03e8973b544</th>\n",
       "      <td>Based on the provided scene graph representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455f7ec-007a-434e-93d1-6d73b1e3746c</th>\n",
       "      <td>Based on the provided scene graph representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327727-8c7a-4cde-8b78-557a5ab9bb70</th>\n",
       "      <td>Based on the provided scene graph representati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   text\n",
       "id                                                                                     \n",
       "2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0  The golden hollow sphere (referred to as purpl...\n",
       "b27163c5-d341-475b-8517-54809872081a  Based on the provided scene graph representati...\n",
       "9bce3140-e8e8-49dd-8574-5e961326fb16  Okay, let's analyze the scene graph and answer...\n",
       "b8df9fbe-07db-46ab-ba17-3713c1632dbd  The golden sphere (referred to as purple_cube ...\n",
       "01c30c62-f489-4246-af18-b7b538b4cb9d  Based on the provided scene graph representati...\n",
       "...                                                                                 ...\n",
       "4073994c-e4ca-4592-b001-fe0a79ab0e3f  Based on the provided scene graph representati...\n",
       "3a158fb7-38cb-49b4-91e8-0cb63d6bf218  Okay, let's analyze the scene graph and answer...\n",
       "247a493d-0d24-4f1b-bbf6-b03e8973b544  Based on the provided scene graph representati...\n",
       "1455f7ec-007a-434e-93d1-6d73b1e3746c  Based on the provided scene graph representati...\n",
       "15327727-8c7a-4cde-8b78-557a5ab9bb70  Based on the provided scene graph representati...\n",
       "\n",
       "[2400 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "with open(WORK_DIR / \"cvrr/cvrr_qa_responses.jsonl\") as f:\n",
    "    predictions = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "# transforming the id key from `qid` to `id` for consistency and `response` to `answer`\n",
    "predictions_df = pd.DataFrame(predictions, dtype='string').rename(columns={'qid':'id'})\n",
    "predictions_df.set_index('id', inplace=True)\n",
    "\n",
    "ans_df = predictions_df\n",
    "ans_df = ans_df.rename(columns={'response': 'text'})\n",
    "ans_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM as judge evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an intelligent chatbot designed for evaluating the correctness of AI assistant predictions for\n",
      "question-answer pairs.\n",
      "Your task is to compare the predicted answer with the ground-truth answer and determine if the predicted\n",
      "answer is correct or not. Here's how you can accomplish the task:\n",
      "------\n",
      "##INSTRUCTIONS:\n",
      "- Focus on the correctness and accuracy of the predicted answer with the ground-truth.\n",
      "- Consider predictions with less specific details as correct evaluation, unless such details are explicitly\n",
      "asked in the question.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(WORK_DIR / 'cvrr/llm_as_judge_sys.txt', 'r') as f:\n",
    "    sys_prompt = f.read()\n",
    "\n",
    "print(sys_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please evaluate the following video-based question-answer pair:\n",
      "Question: {question}\n",
      "Ground truth correct Answer: {gt_answer}\n",
      "Predicted Answer: {prediction}\n",
      "Provide your evaluation as a correct/incorrect prediction along with the score where the score is an\n",
      "integer value between 0 (fully wrong) and 5 (fully correct). The middle score provides the percentage of\n",
      "correctness.\n",
      "Please generate the response in the form of a Python dictionary string with keys 'pred', 'score' and\n",
      "'reason', where value of 'pred' is a string of 'correct' or 'incorrect', value of 'score' is in INTEGER, not STRING\n",
      "and value of 'reason' should provide the reason behind the decision.\n",
      "Only provide the Python dictionary string.\n",
      "For example, your response should look like this: {{'pred': 'correct', 'score': 4, 'reason': reason}}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(WORK_DIR / 'cvrr/llm_as_judge_user.txt', 'r') as f:\n",
    "    user_prompt = f.read()\n",
    "\n",
    "print(user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_prompt_formatter = LlmAsJudgePrompt(user_prompt)\n",
    "judge_cvrr_dataset = JudgeDataset(\n",
    "    dataset=qa_cvrr_dataset,\n",
    "    predictions_filepath=WORK_DIR/\"cvrr/cvrr_qa_responses.jsonl\",\n",
    "    prompt_formatter=judge_prompt_formatter\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension_name': 'Continuity and Object Instance Count',\n",
       " 'subset': 'continuity_and_object_instance_count',\n",
       " 'question_id': '2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0',\n",
       " 'question': 'How many times is the golden hollow sphere gets covered by other objects?',\n",
       " 'video_id': 'continuity_and_object_instance_count_183',\n",
       " 'answer': 'The golden hollow sphere is covered two times by other objects.',\n",
       " 'stsg': '\\nFrame 0:\\n\\n\\npurple_cube ---- above ---- yellow_sphere\\npurple_cube ---- adjacent_to ---- green_cone\\npurple_cube ---- adjacent_to ---- red_cone\\ngreen_cone ---- to_the_left_of ---- purple_cube\\nred_cone ---- to_the_right_of ---- purple_cube\\nyellow_sphere ---- below ---- purple_cube\\ngreen_cone ---- positioned_near ---- purple_cube\\nred_cone ---- positioned_near ---- purple_cube\\nyellow_sphere ---- directly_under ---- purple_cube\\npurple_cube ---- supporting ---- yellow_sphere\\n\\nFrame 1:\\n\\n\\nred_sphere ---- above ---- green_cone\\ngreen_cone ---- above ---- purple_cube\\npurple_cube ---- on ---- surface\\nred_sphere ---- above ---- green_cone\\ngreen_cone ---- looking_at ---- purple_cube\\nred_sphere ---- looking_at ---- green_cone\\npurple_cube ---- on_top_of ---- surface\\ngreen_cone ---- attached_to ---- red_sphere\\nsurface ---- supporting ---- purple_cube\\ngreen_cone ---- positioned_above ---- purple_cube\\nred_sphere ---- positioned_above ---- green_cone\\n\\nFrame 2:\\n\\nred_sphere ---- above ---- purple_cube\\npurple_cube ---- on ---- white_surface\\ngreen_cylinder ---- to_the_right_of ---- purple_cube\\nwhite_surface ---- supporting ---- purple_cube\\nred_sphere ---- looking_at ---- purple_cube\\npurple_cube ---- positioned_on ---- white_surface\\ngreen_cylinder ---- adjacent_to ---- purple_cube\\nwhite_surface ---- containing ---- red_sphere\\nred_sphere ---- positioned_above ---- purple_cube\\ngreen_cylinder ---- near ---- purple_cube\\npurple_cube ---- centered_on ---- white_surface\\n\\nFrame 3:\\n\\npurple_cube ---- sitting_on ---- gray_table\\ngreen_cone ---- positioned_behind ---- purple_cube\\ngray_table ---- supporting ---- purple_cube\\ngray_table ---- adjacent_to ---- gray_chair\\ngray_chair ---- positioned_next_to ---- gray_table\\npurple_cube ---- placed_on ---- gray_table\\ngreen_cone ---- located_behind ---- purple_cube\\ngray_table ---- resting_on ---- gray_floor\\ngray_floor ---- supporting ---- gray_table\\npurple_cube ---- part_of ---- scene\\ngreen_cone ---- part_of ---- scene\\ngray_table ---- part_of ---- scene\\ngray_chair ---- part_of ---- scene\\n\\nFrame 4:\\n\\ngreen_cylinder ---- supporting ---- purple_cube\\npurple_cube ---- resting_on ---- green_cylinder\\ngreen_cylinder ---- positioned_on ---- gray_background\\ngray_background ---- behind ---- green_cylinder\\npurple_cube ---- above ---- green_cylinder\\ngreen_cylinder ---- positioned_above ---- gray_background\\npurple_cube ---- adjacent_to ---- green_cylinder\\ngreen_cylinder ---- centered_on ---- purple_cube\\npurple_cube ---- reflecting_off ---- green_cylinder\\ngray_background ---- providing_backdrop_for ---- green_cylinder\\npurple_cube ---- occupying_space_above ---- green_cylinder\\n',\n",
       " 'qid': '2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0',\n",
       " 'prompt': \"Please evaluate the following video-based question-answer pair:\\nQuestion: How many times is the golden hollow sphere gets covered by other objects?\\nGround truth correct Answer: The golden hollow sphere is covered two times by other objects.\\nPredicted Answer: The golden hollow sphere (referred to as purple_cube in the scene graph) is covered by other objects a total of 4 times across the four frames. Here’s a breakdown:\\n\\n*   **Frame 0:** The purple_cube is directly below the purple_cube, indicating it's covered.\\n*   **Frame 1:** The purple_cube is covered by the red_sphere.\\n*   **Frame 2:** The purple_cube is covered by the red_sphere.\\n*   **Frame 3:** The purple_cube is covered by the red_sphere.\\n\\nTherefore, the purple_cube is covered by the red_sphere in three of the frames.\\nProvide your evaluation as a correct/incorrect prediction along with the score where the score is an\\ninteger value between 0 (fully wrong) and 5 (fully correct). The middle score provides the percentage of\\ncorrectness.\\nPlease generate the response in the form of a Python dictionary string with keys 'pred', 'score' and\\n'reason', where value of 'pred' is a string of 'correct' or 'incorrect', value of 'score' is in INTEGER, not STRING\\nand value of 'reason' should provide the reason behind the decision.\\nOnly provide the Python dictionary string.\\nFor example, your response should look like this: {'pred': 'correct', 'score': 4, 'reason': reason}.\\n\",\n",
       " 'gt_answer': 'The golden hollow sphere is covered two times by other objects.',\n",
       " 'response': \"The golden hollow sphere (referred to as purple_cube in the scene graph) is covered by other objects a total of 4 times across the four frames. Here’s a breakdown:\\n\\n*   **Frame 0:** The purple_cube is directly below the purple_cube, indicating it's covered.\\n*   **Frame 1:** The purple_cube is covered by the red_sphere.\\n*   **Frame 2:** The purple_cube is covered by the red_sphere.\\n*   **Frame 3:** The purple_cube is covered by the red_sphere.\\n\\nTherefore, the purple_cube is covered by the red_sphere in three of the frames.\"}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_cvrr_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please evaluate the following video-based question-answer pair:\n",
      "Question: How many times is the golden hollow sphere gets covered by other objects?\n",
      "Ground truth correct Answer: The golden hollow sphere is covered two times by other objects.\n",
      "Predicted Answer: The golden hollow sphere (referred to as purple_cube in the scene graph) is covered by other objects a total of 4 times across the four frames. Here’s a breakdown:\n",
      "\n",
      "*   **Frame 0:** The purple_cube is directly below the purple_cube, indicating it's covered.\n",
      "*   **Frame 1:** The purple_cube is covered by the red_sphere.\n",
      "*   **Frame 2:** The purple_cube is covered by the red_sphere.\n",
      "*   **Frame 3:** The purple_cube is covered by the red_sphere.\n",
      "\n",
      "Therefore, the purple_cube is covered by the red_sphere in three of the frames.\n",
      "Provide your evaluation as a correct/incorrect prediction along with the score where the score is an\n",
      "integer value between 0 (fully wrong) and 5 (fully correct). The middle score provides the percentage of\n",
      "correctness.\n",
      "Please generate the response in the form of a Python dictionary string with keys 'pred', 'score' and\n",
      "'reason', where value of 'pred' is a string of 'correct' or 'incorrect', value of 'score' is in INTEGER, not STRING\n",
      "and value of 'reason' should provide the reason behind the decision.\n",
      "Only provide the Python dictionary string.\n",
      "For example, your response should look like this: {'pred': 'correct', 'score': 4, 'reason': reason}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(judge_cvrr_dataset[0]['prompt'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the the Judge evaluation\n",
    "\n",
    "Now we load the judge evaluation on the responses of the perdictor model. The set of responses are saved in two different files. `llama8b_as_judge_wrong.jsonl` contains the responses that were classified as incorrect by the method with the method extraction, `llama8b_as_judge_correct.jsonl` contains the responses classified as correct.  \n",
    "These two files contains only the responses for which it was able to extract an answer with the regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2400 entries, 2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0 to 15327727-8c7a-4cde-8b78-557a5ab9bb70\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   response  2400 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 37.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the scores for the wrong answers\n",
    "predictions = []\n",
    "with open(WORK_DIR / \"cvrr/cvrr_val_judge_evaluation.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    predictions = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "# Extract pred, score and reason from response dictionary into separate columns\n",
    "judge_pred_df = pd.DataFrame(predictions).rename(columns={'qid':'id'})\n",
    "judge_pred_df.set_index('id', inplace=True)\n",
    "judge_pred_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle formatting issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gemma we need to be more careful becuase the format is different, it encapsulated the json output in the with the tokens: \n",
    "```\n",
    "```json\\n\n",
    "<actual_answer>\n",
    "\\n```\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total answers: 2400\n",
      "Answers following JSON template: 2392\n",
      "Percentage following JSON template: 99.67%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create mask for answers that follow JSON syntax\n",
    "json_mask = judge_pred_df['response'].str.match(r'^(```json\\s)?({[^}]+})(\\s```)?$')\n",
    "matches_json_template = json_mask.sum()\n",
    "\n",
    "print(f\"Total answers: {len(judge_pred_df)}\")\n",
    "print(f\"Answers following JSON template: {matches_json_template}\")\n",
    "print(f\"Percentage following JSON template: {(matches_json_template/len(judge_pred_df))*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2392 entries, 2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0 to 15327727-8c7a-4cde-8b78-557a5ab9bb70\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   response  2392 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 37.4+ KB\n"
     ]
    }
   ],
   "source": [
    "judge_pred_df.loc[json_mask, 'response'] = \\\n",
    "    judge_pred_df.loc[json_mask, 'response'] \\\n",
    "    .apply(lambda x: re.search(r'^(?:```json\\s)?({[^}]+})(?:\\s```)?$', x).group(1))\n",
    "\n",
    "judge_pred_df.loc[~json_mask, 'response'] = \"\"\n",
    "judge_pred_df = judge_pred_df.loc[json_mask]\n",
    "judge_pred_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace new line (lead to EOF Errors) with whitespace\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df['response'].str.replace('\\n+', ' ', regex=True)\n",
    "\n",
    "# Replace lef and right quotation mark with simple quotation mark\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df['response'].str.replace('[\\u2018-\\u201b]', '\\'', regex=True)\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df['response'].str.replace('[\\u201c\\u201d]', '\"', regex=True)\n",
    "# ------------------ Removing inner double quotes --------------------\n",
    "# It may happen that the text may contain inner double quotes before the\n",
    "# attribute end. This will cause the parser to termiate early and spout\n",
    "# errors for the remaining text. With this snippet we replace those inner\n",
    "# double quotes with single quotes.\n",
    "#  \n",
    "# we first match the text of the reason paramter inside the double quotes\n",
    "# then we escape/replace all the double quotes inside the text\n",
    "inside_doublequotes = r\"(?<=\\\"reason\\\": \\\")(.*)(?=\\\"(?:,|}))\"\n",
    "\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df.apply(\n",
    "        func=lambda row: re.sub(\n",
    "            inside_doublequotes, \n",
    "            lambda matchobj: matchobj.group(0).replace('\\\"', ''), \n",
    "            row['response']),\n",
    "        axis=1\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2392 entries, 2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0 to 15327727-8c7a-4cde-8b78-557a5ab9bb70\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   response  2392 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 37.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# sometimes the model writes outside the {...} bounderies\n",
    "# let's keep only the relevant part\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df.apply(\n",
    "        func=lambda row: re.sub(\n",
    "            r\"(\\{.*\\})(.*)\", \n",
    "            r\"\\1\", \n",
    "            row['response']),\n",
    "        axis=1\n",
    "        )\n",
    "    \n",
    "# some times the model starts the answer with \\\" but then terminates it with \\'\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df.apply(\n",
    "        func=lambda row: re.sub( \n",
    "            r\"(?<=\\'reason\\':)\\s+\\\"(.*)\\'\\s*(?=})\", \n",
    "            lambda matchobj:\"\\\"\" + matchobj.group(1) + \"\\\"\", \n",
    "            row['response']),\n",
    "        axis=1\n",
    "        )\n",
    "    \n",
    "# some times the model starts the answer with \\' but then terminates it with \\\"\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df.apply(\n",
    "        func=lambda row: re.sub( \n",
    "            r\"(?<=\\'reason\\':)\\s+\\'(.*)\\\"\\s*(?=})\", \n",
    "            lambda matchobj:\"\\\"\" + matchobj.group(1) + \"\\\"\", \n",
    "            row['response']),\n",
    "        axis=1\n",
    "        )\n",
    "\n",
    "    \n",
    "# some times the model is enclosed by \\' \\'\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df.apply(\n",
    "        func=lambda row: re.sub(\n",
    "            r\"(?<=\\'reason\\':)\\s+\\'(.*)\\'\\s*(?=})\", \n",
    "            lambda matchobj: \"\\\"\" + matchobj.group(1)+ \"\\\"\", \n",
    "            row['response']),\n",
    "        axis=1\n",
    "        )\n",
    "    \n",
    "\n",
    "\n",
    "# ------------------ Removing inner double quotes --------------------\n",
    "# It may happen that the text may contain inner double quotes before the\n",
    "# attribute end. This will cause the parser to termiate early and spout\n",
    "# errors for the remaining text. With this snippet we replace those inner\n",
    "# double quotes with single quotes.\n",
    "#  \n",
    "# we first match the text of the reason paramter inside the double quotes\n",
    "# then we escape/replace all the double quotes inside the text\n",
    "inside_doublequotes = r\"(\\'reason\\':\\s*\\\")(.*)(?=\\\"(?:,|}))\"\n",
    "\n",
    "judge_pred_df['response'] = \\\n",
    "    judge_pred_df.apply(\n",
    "        func=lambda row: re.sub(\n",
    "            inside_doublequotes, \n",
    "            lambda matchobj: matchobj.group(1) + matchobj.group(2).replace('\\\"', ''), \n",
    "            row['response']),\n",
    "        axis=1\n",
    "        )\n",
    "\n",
    "judge_pred_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The predicted answer incorrectly states the go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b27163c5-d341-475b-8517-54809872081a</th>\n",
       "      <td>correct</td>\n",
       "      <td>5</td>\n",
       "      <td>The predicted answer accurately reflects the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9bce3140-e8e8-49dd-8574-5e961326fb16</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The predicted answer provides a detailed break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8df9fbe-07db-46ab-ba17-3713c1632dbd</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The predicted answer contradicts the ground tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01c30c62-f489-4246-af18-b7b538b4cb9d</th>\n",
       "      <td>correct</td>\n",
       "      <td>5</td>\n",
       "      <td>The predicted answer accurately identifies and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073994c-e4ca-4592-b001-fe0a79ab0e3f</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The ground truth explicitly states that the vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a158fb7-38cb-49b4-91e8-0cb63d6bf218</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The predicted answer provides a detailed break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247a493d-0d24-4f1b-bbf6-b03e8973b544</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The ground truth states the woman is performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455f7ec-007a-434e-93d1-6d73b1e3746c</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks about the direction of movem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327727-8c7a-4cde-8b78-557a5ab9bb70</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The question asks about the direction of the c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pred  score  \\\n",
       "id                                                       \n",
       "2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0  incorrect      2   \n",
       "b27163c5-d341-475b-8517-54809872081a    correct      5   \n",
       "9bce3140-e8e8-49dd-8574-5e961326fb16  incorrect      2   \n",
       "b8df9fbe-07db-46ab-ba17-3713c1632dbd  incorrect      1   \n",
       "01c30c62-f489-4246-af18-b7b538b4cb9d    correct      5   \n",
       "...                                         ...    ...   \n",
       "4073994c-e4ca-4592-b001-fe0a79ab0e3f  incorrect      1   \n",
       "3a158fb7-38cb-49b4-91e8-0cb63d6bf218  incorrect      1   \n",
       "247a493d-0d24-4f1b-bbf6-b03e8973b544  incorrect      2   \n",
       "1455f7ec-007a-434e-93d1-6d73b1e3746c  incorrect      1   \n",
       "15327727-8c7a-4cde-8b78-557a5ab9bb70  incorrect      2   \n",
       "\n",
       "                                                                                 reason  \n",
       "id                                                                                       \n",
       "2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0  The predicted answer incorrectly states the go...  \n",
       "b27163c5-d341-475b-8517-54809872081a  The predicted answer accurately reflects the i...  \n",
       "9bce3140-e8e8-49dd-8574-5e961326fb16  The predicted answer provides a detailed break...  \n",
       "b8df9fbe-07db-46ab-ba17-3713c1632dbd  The predicted answer contradicts the ground tr...  \n",
       "01c30c62-f489-4246-af18-b7b538b4cb9d  The predicted answer accurately identifies and...  \n",
       "...                                                                                 ...  \n",
       "4073994c-e4ca-4592-b001-fe0a79ab0e3f  The ground truth explicitly states that the vi...  \n",
       "3a158fb7-38cb-49b4-91e8-0cb63d6bf218  The predicted answer provides a detailed break...  \n",
       "247a493d-0d24-4f1b-bbf6-b03e8973b544  The ground truth states the woman is performin...  \n",
       "1455f7ec-007a-434e-93d1-6d73b1e3746c  The question asks about the direction of movem...  \n",
       "15327727-8c7a-4cde-8b78-557a5ab9bb70  The question asks about the direction of the c...  \n",
       "\n",
       "[2392 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract pred, score and reason from response dictionary into separate columns\n",
    "judge_pred_df['pred'] = \\\n",
    "    judge_pred_df['response'] \\\n",
    "    .apply(lambda x: eval(x)['pred']) \\\n",
    "    .astype('string') \n",
    "\n",
    "judge_pred_df['score'] = \\\n",
    "    judge_pred_df['response'] \\\n",
    "    .apply(lambda x: int(eval(x)['score'])) \\\n",
    "    .astype('int32')\n",
    "\n",
    "judge_pred_df['reason'] = \\\n",
    "    judge_pred_df['response'] \\\n",
    "    .apply(lambda x: eval(x)['reason']) \\\n",
    "    .astype('string')\n",
    "\n",
    "judge_pred_df.drop('response', axis=1, inplace=True)\n",
    "judge_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The predicted answer incorrectly states the go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b27163c5-d341-475b-8517-54809872081a</th>\n",
       "      <td>correct</td>\n",
       "      <td>5</td>\n",
       "      <td>The predicted answer accurately reflects the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9bce3140-e8e8-49dd-8574-5e961326fb16</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The predicted answer provides a detailed break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8df9fbe-07db-46ab-ba17-3713c1632dbd</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The predicted answer contradicts the ground tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01c30c62-f489-4246-af18-b7b538b4cb9d</th>\n",
       "      <td>correct</td>\n",
       "      <td>5</td>\n",
       "      <td>The predicted answer accurately identifies and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073994c-e4ca-4592-b001-fe0a79ab0e3f</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The ground truth explicitly states that the vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a158fb7-38cb-49b4-91e8-0cb63d6bf218</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The predicted answer provides a detailed break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247a493d-0d24-4f1b-bbf6-b03e8973b544</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The ground truth states the woman is performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455f7ec-007a-434e-93d1-6d73b1e3746c</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks about the direction of movem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327727-8c7a-4cde-8b78-557a5ab9bb70</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The question asks about the direction of the c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pred  score  \\\n",
       "id                                                       \n",
       "2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0  incorrect      2   \n",
       "b27163c5-d341-475b-8517-54809872081a    correct      5   \n",
       "9bce3140-e8e8-49dd-8574-5e961326fb16  incorrect      2   \n",
       "b8df9fbe-07db-46ab-ba17-3713c1632dbd  incorrect      1   \n",
       "01c30c62-f489-4246-af18-b7b538b4cb9d    correct      5   \n",
       "...                                         ...    ...   \n",
       "4073994c-e4ca-4592-b001-fe0a79ab0e3f  incorrect      1   \n",
       "3a158fb7-38cb-49b4-91e8-0cb63d6bf218  incorrect      1   \n",
       "247a493d-0d24-4f1b-bbf6-b03e8973b544  incorrect      2   \n",
       "1455f7ec-007a-434e-93d1-6d73b1e3746c  incorrect      1   \n",
       "15327727-8c7a-4cde-8b78-557a5ab9bb70  incorrect      2   \n",
       "\n",
       "                                                                                 reason  \n",
       "id                                                                                       \n",
       "2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0  The predicted answer incorrectly states the go...  \n",
       "b27163c5-d341-475b-8517-54809872081a  The predicted answer accurately reflects the i...  \n",
       "9bce3140-e8e8-49dd-8574-5e961326fb16  The predicted answer provides a detailed break...  \n",
       "b8df9fbe-07db-46ab-ba17-3713c1632dbd  The predicted answer contradicts the ground tr...  \n",
       "01c30c62-f489-4246-af18-b7b538b4cb9d  The predicted answer accurately identifies and...  \n",
       "...                                                                                 ...  \n",
       "4073994c-e4ca-4592-b001-fe0a79ab0e3f  The ground truth explicitly states that the vi...  \n",
       "3a158fb7-38cb-49b4-91e8-0cb63d6bf218  The predicted answer provides a detailed break...  \n",
       "247a493d-0d24-4f1b-bbf6-b03e8973b544  The ground truth states the woman is performin...  \n",
       "1455f7ec-007a-434e-93d1-6d73b1e3746c  The question asks about the direction of movem...  \n",
       "15327727-8c7a-4cde-8b78-557a5ab9bb70  The question asks about the direction of the c...  \n",
       "\n",
       "[2392 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2392, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_pred_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      "------------------------------\n",
      "incorrect :  60.03%\n",
      "correct   :  39.97%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred_percentages = judge_pred_df['pred'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"{'incorrect':10}: {pred_percentages['incorrect']:6.2f}%\\n\"\n",
    "      f\"{'correct':10}: {pred_percentages['correct']:6.2f}%\")\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze some of the answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's inspect more samples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The predicted answer incorrectly states the go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b27163c5-d341-475b-8517-54809872081a</th>\n",
       "      <td>correct</td>\n",
       "      <td>5</td>\n",
       "      <td>The predicted answer accurately reflects the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9bce3140-e8e8-49dd-8574-5e961326fb16</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The predicted answer provides a detailed break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8df9fbe-07db-46ab-ba17-3713c1632dbd</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The predicted answer contradicts the ground tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01c30c62-f489-4246-af18-b7b538b4cb9d</th>\n",
       "      <td>correct</td>\n",
       "      <td>5</td>\n",
       "      <td>The predicted answer accurately identifies and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073994c-e4ca-4592-b001-fe0a79ab0e3f</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The ground truth explicitly states that the vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a158fb7-38cb-49b4-91e8-0cb63d6bf218</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The predicted answer provides a detailed break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247a493d-0d24-4f1b-bbf6-b03e8973b544</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The ground truth states the woman is performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455f7ec-007a-434e-93d1-6d73b1e3746c</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks about the direction of movem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15327727-8c7a-4cde-8b78-557a5ab9bb70</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>2</td>\n",
       "      <td>The question asks about the direction of the c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pred  score  \\\n",
       "id                                                       \n",
       "2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0  incorrect      2   \n",
       "b27163c5-d341-475b-8517-54809872081a    correct      5   \n",
       "9bce3140-e8e8-49dd-8574-5e961326fb16  incorrect      2   \n",
       "b8df9fbe-07db-46ab-ba17-3713c1632dbd  incorrect      1   \n",
       "01c30c62-f489-4246-af18-b7b538b4cb9d    correct      5   \n",
       "...                                         ...    ...   \n",
       "4073994c-e4ca-4592-b001-fe0a79ab0e3f  incorrect      1   \n",
       "3a158fb7-38cb-49b4-91e8-0cb63d6bf218  incorrect      1   \n",
       "247a493d-0d24-4f1b-bbf6-b03e8973b544  incorrect      2   \n",
       "1455f7ec-007a-434e-93d1-6d73b1e3746c  incorrect      1   \n",
       "15327727-8c7a-4cde-8b78-557a5ab9bb70  incorrect      2   \n",
       "\n",
       "                                                                                 reason  \n",
       "id                                                                                       \n",
       "2a49d339-11d1-4c70-b6df-8f3f1e4bbcc0  The predicted answer incorrectly states the go...  \n",
       "b27163c5-d341-475b-8517-54809872081a  The predicted answer accurately reflects the i...  \n",
       "9bce3140-e8e8-49dd-8574-5e961326fb16  The predicted answer provides a detailed break...  \n",
       "b8df9fbe-07db-46ab-ba17-3713c1632dbd  The predicted answer contradicts the ground tr...  \n",
       "01c30c62-f489-4246-af18-b7b538b4cb9d  The predicted answer accurately identifies and...  \n",
       "...                                                                                 ...  \n",
       "4073994c-e4ca-4592-b001-fe0a79ab0e3f  The ground truth explicitly states that the vi...  \n",
       "3a158fb7-38cb-49b4-91e8-0cb63d6bf218  The predicted answer provides a detailed break...  \n",
       "247a493d-0d24-4f1b-bbf6-b03e8973b544  The ground truth states the woman is performin...  \n",
       "1455f7ec-007a-434e-93d1-6d73b1e3746c  The question asks about the direction of movem...  \n",
       "15327727-8c7a-4cde-8b78-557a5ab9bb70  The question asks about the direction of the c...  \n",
       "\n",
       "[2392 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   dimension_name  2400 non-null   object\n",
      " 1   subset          2400 non-null   object\n",
      " 2   question_id     2400 non-null   object\n",
      " 3   question        2400 non-null   object\n",
      " 4   video_id        2400 non-null   object\n",
      " 5   answer          2400 non-null   object\n",
      " 6   stsg            2087 non-null   object\n",
      " 7   qid             2400 non-null   object\n",
      " 8   prompt          2400 non-null   object\n",
      " 9   gt_answer       2400 non-null   object\n",
      " 10  response        2400 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 206.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cvrr_dataset_df = pd.DataFrame([i for i in judge_cvrr_dataset])\n",
    "cvrr_dataset_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrr_dataset_df.set_index('question_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 8360cc82-51c9-4b1e-a8b5-bb5d07e6c5c6\n",
      "Question: Does the cleaner take a break to drink water during the task?\n",
      "\n",
      "Ground truth answer:\n",
      "No, there is no depiction of the cleaner taking a break or drinking water.\n",
      "\n",
      "LLM prediction:\n",
      "Based on the provided scene graph representation, the question \"Does the cleaner take a break to drink water during the task?\" cannot be definitively answered.\n",
      "\n",
      "Here’s why:\n",
      "\n",
      "*   **Lack of Temporal Information:** The scene graph only provides information for two frames (Frame 0 and Frame 1). It doesn't include any temporal data indicating a break or the action of drinking water.\n",
      "*   **No Action of Drinking:** There are no objects, attributes, or relationships that describe someone drinking water. The scene graph focuses on the location of objects and their relationships, but doesn’t capture any actions like taking a break or consuming liquids.\n",
      "*   **Focus on Location:** The scene graph primarily describes the location and arrangement of objects – a young man near a black car and a wall. It doesn’t detail any activities or behaviors.\n",
      "\n",
      "Therefore, while the scene graph provides context about the environment and the presence of a young man, it lacks the necessary information to determine if he takes a break to drink water.\n",
      "\n",
      "Judge evlauation:\n",
      " - verdict: correct\n",
      " - score: 5\n",
      " - reason: The predicted answer accurately identifies the limitations of the scene graph in answering the question. It correctly states that the scene graph lacks temporal information and doesn't depict any actions like drinking water, aligning perfectly with the ground truth. The detailed explanation is also well-reasoned and justifies the inability to answer the question based on the provided data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "judged_correct_mask = (judge_pred_df['pred'] == 'correct')\n",
    "idx = \"8360cc82-51c9-4b1e-a8b5-bb5d07e6c5c6\"\n",
    "\n",
    "\n",
    "print(f\"Index: {idx}\")\n",
    "print(f\"Question: {cvrr_dataset_df.loc[idx]['question']}\")\n",
    "print(f\"\\nGround truth answer:\\n{cvrr_dataset_df.loc[idx]['answer']}\")\n",
    "print(f\"\\nLLM prediction:\\n{ans_df.loc[idx]['text']}\")\n",
    "print(f\"\\nJudge evlauation:\\n\"\n",
    "      f\" - verdict: {judge_pred_df.loc[idx]['pred']}\\n\"\n",
    "      f\" - score: {judge_pred_df.loc[idx]['score']}\\n\"\n",
    "      f\" - reason: {judge_pred_df.loc[idx]['reason']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see the score distribution for all the predictions\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=judge_pred_df['score'], discrete=True)\n",
    "plt.title('Distribution of Judge Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
